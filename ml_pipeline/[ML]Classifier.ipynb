{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffb9dde-f66b-45fe-bb1f-175157ea44c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, random, time, joblib, json, shutil\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7159fb97-2705-4ff3-bab1-28292bd16be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Config loaded: K800_H576_S16_WGT\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    'FEATURE_ID': 'K800_H576_S16_WGT', # 피처 캐시 ID\n",
    "    'K_VOCAB_SIZE': 800,\n",
    "    'SIFT_STEP': 16,\n",
    "    'HOG_CELL': 64,\n",
    "    'HOG_BLOCK': 128,\n",
    "    'HOG_STRIDE': 64,\n",
    "    'COLOR_BINS': 16,\n",
    "    'W_BOVW': 1.0,\n",
    "    'W_HOG': 0.5,\n",
    "    'W_COLOR': 1.0,\n",
    "    'CLASSIFIER': 'SVC',\n",
    "    'C': 2.0,\n",
    "    'KERNEL': 'rbf',\n",
    "    'GAMMA': 'scale'\n",
    "}\n",
    "\n",
    "#Data path and Global variable\n",
    "DATA_DIR = '../data'\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train', 'images')\n",
    "TRAIN_LBL_DIR = os.path.join(DATA_DIR, 'train', 'labels')\n",
    "VALID_IMG_DIR = os.path.join(DATA_DIR, 'valid', 'images')\n",
    "VALID_LBL_DIR = os.path.join(DATA_DIR, 'valid', 'labels')\n",
    "BASE_CACHE_DIR = './cache_experiments'\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"Ants\",\"Bees\",\"Beetles\",\"Caterpillars\",\"Earthworms\",\"Earwigs\",\n",
    "    \"Grasshoppers\",\"Moths\",\"Slugs\",\"Snails\",\"Wasps\",\"Weevils\"\n",
    "]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "STD_WINDOW_SIZE = (320, 320)\n",
    "BATCH_SIZE = 128\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "print(f\"Base Config loaded: {BASE_CONFIG['FEATURE_ID']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1820e7-2f45-4bc3-9569-db9b66e9646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Feature Extractors\n",
    "\n",
    "def get_hog_features(img, std_size, cell_size, block_size, stride, nbins=9):\n",
    "    win_size = std_size\n",
    "    block_size_param = (block_size, block_size)\n",
    "    block_stride = (stride, stride)\n",
    "    cell_size_param = (cell_size, cell_size)\n",
    "    if img.shape[:2] != std_size[::-1]:\n",
    "        img = cv2.resize(img, std_size)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size_param, block_stride, cell_size_param, nbins)\n",
    "    return hog.compute(gray).flatten()\n",
    "\n",
    "def get_color_histogram(img, bins):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    chans = cv2.split(hsv)\n",
    "    hists = [cv2.calcHist([c],[0],None,[bins],[0,256]) for c in chans]\n",
    "    for h in hists: cv2.normalize(h, h)\n",
    "    return np.hstack([h.flatten() for h in hists])\n",
    "\n",
    "def get_dense_sift(img, step):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kps = [cv2.KeyPoint(x, y, step) for y in range(0, gray.shape[0], step) for x in range(0, gray.shape[1], step)]\n",
    "    _, desc = sift.compute(gray, kps)\n",
    "    return desc\n",
    "\n",
    "def get_dense_sift_for_batch(imgs, cfg):\n",
    "    return [get_dense_sift(im, step=cfg['SIFT_STEP']) for im in imgs]\n",
    "\n",
    "def create_bovw_histograms(desc_list, vocab):\n",
    "    k = vocab.n_clusters\n",
    "    feats = np.zeros((len(desc_list), k), np.float32)\n",
    "    for i, d in enumerate(desc_list):\n",
    "        if d is not None:\n",
    "            words = vocab.predict(d)\n",
    "            hist, _ = np.histogram(words, bins=np.arange(k+1))\n",
    "            if hist.sum() > 0: hist = hist / np.linalg.norm(hist)\n",
    "            feats[i] = hist\n",
    "    return feats\n",
    "\n",
    "def create_combined_features(imgs, vocab, cfg, desc_list=None):\n",
    "    if desc_list is None: desc_list = get_dense_sift_for_batch(imgs, cfg)\n",
    "    bovw = create_bovw_histograms(desc_list, vocab)\n",
    "    weighted_bovw = cfg['W_BOVW'] * bovw\n",
    "    hog_color = []\n",
    "    for im in imgs:\n",
    "        h = get_hog_features(im, STD_WINDOW_SIZE, cfg['HOG_CELL'], cfg['HOG_BLOCK'], cfg['HOG_STRIDE'])\n",
    "        c = get_color_histogram(im, bins=cfg['COLOR_BINS'])\n",
    "        hog_color.append(np.hstack((cfg['W_HOG']*h, cfg['W_COLOR']*c)))\n",
    "    return np.hstack((weighted_bovw, np.array(hog_color)))\n",
    "\n",
    "#Data Loader & Cache Manager\n",
    "def load_yolo_crops(img_dir, lbl_dir, std_size):\n",
    "    cropped_img, labels, counts = [], [], defaultdict(int)\n",
    "    for f in os.listdir(lbl_dir):\n",
    "        if not f.endswith('.txt'): continue\n",
    "        img_path = os.path.join(img_dir, os.path.splitext(f)[0] + '.jpg')\n",
    "        if not os.path.exists(img_path): continue\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h, w, _ = img.shape\n",
    "        for line in open(os.path.join(lbl_dir, f)):\n",
    "            try:\n",
    "                cid, x, y, wn, hn = map(float, line.split())\n",
    "                cid = int(cid)\n",
    "                x1, y1 = int((x-wn/2)*w), int((y-hn/2)*h)\n",
    "                x2, y2 = int((x+wn/2)*w), int((y+hn/2)*h)\n",
    "                crop = img[max(0,y1):min(h,y2), max(0,x1):min(w,x2)]\n",
    "                if crop.size>0:\n",
    "                    cropped_img.append(cv2.resize(crop, std_size))\n",
    "                    labels.append(cid)\n",
    "                    counts[cid]+=1\n",
    "            except: continue\n",
    "    print(f\"Loaded {len(cropped_img)} validation crops.\")\n",
    "    return cropped_img, np.array(labels)\n",
    "\n",
    "def create_yolo_image(img_dir, lbl_dir, std_size, batch_size):\n",
    "    files = os.listdir(lbl_dir)\n",
    "    random.shuffle(files)\n",
    "    imgs, lbls = [], []\n",
    "    for f in files:\n",
    "        if not f.endswith('.txt'): continue\n",
    "        imgp = os.path.join(img_dir, os.path.splitext(f)[0] + '.jpg')\n",
    "        if not os.path.exists(imgp): continue\n",
    "        img = cv2.imread(imgp)\n",
    "        if img is None: continue\n",
    "        h,w,_ = img.shape\n",
    "        for line in open(os.path.join(lbl_dir, f)):\n",
    "            try:\n",
    "                cid,x,y,wn,hn = map(float, line.split())\n",
    "                cid=int(cid)\n",
    "                x1,y1=int((x-wn/2)*w),int((y-hn/2)*h)\n",
    "                x2,y2=int((x+wn/2)*w),int((y+hn/2)*h)\n",
    "                crop=img[max(0,y1):min(h,y2),max(0,x1):min(w,x2)]\n",
    "                if crop.size>0:\n",
    "                    imgs.append(cv2.resize(crop,std_size))\n",
    "                    lbls.append(cid)\n",
    "                    if len(imgs)>=batch_size:\n",
    "                        yield np.array(imgs), np.array(lbls)\n",
    "                        imgs, lbls = [], []\n",
    "            except: continue\n",
    "    if imgs: yield np.array(imgs), np.array(lbls)\n",
    "\n",
    "def get_features(cfg):\n",
    "    fid = cfg['FEATURE_ID']\n",
    "    d = os.path.join(BASE_CACHE_DIR, fid)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    paths = {k: os.path.join(d, f'{k}.npy') for k in ['X_train','y_train','X_val','y_val']}\n",
    "    vocab_path = os.path.join(d, 'vocab.pkl')\n",
    "\n",
    "    try:\n",
    "        if all(os.path.exists(p) for p in paths.values()) and os.path.exists(vocab_path):\n",
    "            print(f\"Cached features found for [{fid}]. Loading...\")\n",
    "            x_train = np.load(paths['X_train'], mmap_mode='r')\n",
    "            y_train = np.load(paths['y_train'])\n",
    "            x_val = np.load(paths['X_val'], mmap_mode='r')\n",
    "            y_val = np.load(paths['y_val'])\n",
    "            vocab = joblib.load(vocab_path)\n",
    "            return x_train, y_train, x_val, y_val, vocab\n",
    "    except Exception as e:\n",
    "        print(f\"Cache error: {e}, regenerating...\")\n",
    "\n",
    "    print(f\"Generating features for [{fid}]...\")\n",
    "    start = time.time()\n",
    "    vocab = MiniBatchKMeans(n_clusters=cfg['K_VOCAB_SIZE'], random_state=42,\n",
    "                            batch_size=512, n_init=5, max_iter=150)\n",
    "    for imgs, _ in create_yolo_image(TRAIN_IMG_DIR, TRAIN_LBL_DIR, STD_WINDOW_SIZE, BATCH_SIZE):\n",
    "        descs = get_dense_sift_for_batch(imgs, cfg)\n",
    "        flat = np.vstack([d for d in descs if d is not None])\n",
    "        if flat.size>0: vocab.partial_fit(flat)\n",
    "    joblib.dump(vocab, vocab_path)\n",
    "    x_train, y_train = [], []\n",
    "    for imgs, labels in create_yolo_image(TRAIN_IMG_DIR, TRAIN_LBL_DIR, STD_WINDOW_SIZE, BATCH_SIZE):\n",
    "        x_train.append(create_combined_features(imgs, vocab, cfg))\n",
    "        y_train.append(labels)\n",
    "    x_train, y_train = np.vstack(x_train), np.hstack(y_train)\n",
    "    x_val_imgs, y_val = load_yolo_crops(VALID_IMG_DIR, VALID_LBL_DIR, STD_WINDOW_SIZE)\n",
    "    x_val = create_combined_features(x_val_imgs, vocab, cfg)\n",
    "    for k, v in zip(paths.keys(), [x_train,y_train,x_val,y_val]): np.save(paths[k], v)\n",
    "    print(f\"Features saved ({(time.time()-start)/60:.1f} min)\")\n",
    "    return x_train, y_train, x_val, y_val, vocab\n",
    "\n",
    "print(\"All helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20591fd6-cc78-4884-84c9-779a30187dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached features found for [K800_H576_S16_WGT]. Loading...\n"
     ]
    }
   ],
   "source": [
    "# Extract feature or load from cache \n",
    "x_tr, y_tr, x_v, y_v, vocab = get_features(BASE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a6bc0c-cbe7-4bfe-baa8-ddc614b99f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model: SVC(C=2.0)...\n",
      "Model fitted in 122.93s\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(\n",
    "        C=BASE_CONFIG['C'],\n",
    "        kernel=BASE_CONFIG['KERNEL'],\n",
    "        gamma=BASE_CONFIG['GAMMA'],\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Fitting Model: SVC(C={BASE_CONFIG['C']})...\")\n",
    "start_time = time.time()\n",
    "model_pipeline.fit(x_tr, y_tr) \n",
    "print(f\"Model fitted in {time.time() - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11b823a-8603-438a-9d56-c33fd804f43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier model saved to: ./saved_models/classifier_K800_H576_S16_WGT.pkl\n",
      "BoVW Vocab saved to: ./saved_models/vocab_K800_H576_S16_WGT.pkl\n"
     ]
    }
   ],
   "source": [
    "#Save Models\n",
    "MODEL_DIR = './saved_models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "#Classifier Pipeline \n",
    "model_filename = os.path.join(MODEL_DIR, f\"classifier_{BASE_CONFIG['FEATURE_ID']}.pkl\")\n",
    "joblib.dump(model_pipeline, model_filename)\n",
    "\n",
    "#BoVW  \n",
    "vocab_source_path = os.path.join(BASE_CACHE_DIR,BASE_CONFIG['FEATURE_ID'], 'vocab.pkl')\n",
    "vocab_dest_path = os.path.join(MODEL_DIR, f\"vocab_{BASE_CONFIG['FEATURE_ID']}.pkl\")\n",
    "shutil.copyfile(vocab_source_path, vocab_dest_path)\n",
    "\n",
    "print(f\"\\nClassifier model saved to: {model_filename}\")\n",
    "print(f\"BoVW Vocab saved to: {vocab_dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74e900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (COMP9517)",
   "language": "python",
   "name": "comp9517"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
