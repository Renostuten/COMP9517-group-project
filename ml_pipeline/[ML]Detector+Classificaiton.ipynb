{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390342c5",
   "metadata": {},
   "source": [
    "# Environment Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c97cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import, Parameters\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, random, glob\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "#Scikit-learn & Skimage\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from skimage.feature import hog\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# 1. Configuration\n",
    "DATA_DIR = '../data'\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train', 'images')\n",
    "TRAIN_LBL_DIR = os.path.join(DATA_DIR, 'train', 'labels')\n",
    "VAL_IMG_DIR   = os.path.join(DATA_DIR, 'valid', 'images')\n",
    "VAL_LBL_DIR   = os.path.join(DATA_DIR, 'valid', 'labels')\n",
    "TEST_IMG_DIR   = os.path.join(DATA_DIR, 'test', 'images')\n",
    "TEST_LBL_DIR   = os.path.join(DATA_DIR, 'test', 'labels')\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"Ants\",\"Bees\",\"Beetles\",\"Caterpillars\",\"Earthworms\",\"Earwigs\",\n",
    "    \"Grasshoppers\",\"Moths\",\"Slugs\",\"Snails\",\"Wasps\",\"Weevils\"\n",
    "]\n",
    "\n",
    "#Classifier Config\n",
    "CLF_CONFIG = {\n",
    "    'K_VOCAB_SIZE': 800,\n",
    "    'SIFT_STEP': 16,\n",
    "    'HOG_CELL': 64, 'HOG_BLOCK': 128, 'HOG_STRIDE': 64,\n",
    "    'COLOR_BINS': 16,\n",
    "    'W_BOVW': 1.0, 'W_HOG': 0.5, 'W_COLOR': 1.0,\n",
    "    'C': 2.0, 'KERNEL': 'rbf', 'GAMMA': 'scale',\n",
    "    'STD_SIZE': (320, 320)\n",
    "}\n",
    "\n",
    "#Detector Config\n",
    "DET_SCORE_THRESH  = 0.5\n",
    "DET_NMS_IOU_THR   = 0.3\n",
    "PATCH_SIZE         = (128, 128)\n",
    "HOG_ORIENTATIONS   = 9\n",
    "HOG_PIXELS_PER_CELL = (8, 8)\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)\n",
    "HOG_BLOCK_NORM     = 'L2-Hys'\n",
    "HOG_TRANSFORM_SQRT = True\n",
    "SVM_C            = 1.0\n",
    "SVM_CLASS_WEIGHT = \"balanced\"\n",
    "SVM_MAX_ITER     = 5000\n",
    "SVM_RANDOM_STATE = 0\n",
    "BACKGROUND_LABEL = 0\n",
    "INSECT_LABEL     = 1\n",
    "\n",
    "#Preprocessing Config\n",
    "BORDER_PX      = 13\n",
    "COLOR_SPACE    = \"LAB\"\n",
    "COLOR_WEIGHT   = 1.6\n",
    "EDGE_WEIGHT    = 2.75\n",
    "GAUSS_KSIZE    = 5\n",
    "CC_CONNECT     = 8\n",
    "AREA_MIN_RATIO = 0.03\n",
    "AREA_MAX_RATIO = 0.45\n",
    "OTSU_BIAS      = 0.00\n",
    "\n",
    "#Sampling Config\n",
    "TRAIN_MAX_IMAGES      = 11000\n",
    "VAL_MAX_IMAGES        = None\n",
    "MAX_POS_PER_IMG       = 50\n",
    "NEG_POS_RATIO         = 2.0\n",
    "NEG_IOU_THR           = 0.1\n",
    "BG_MAX_ATTEMPTS_FACTOR = 50\n",
    "\n",
    "#Global Objects\n",
    "sift = cv2.SIFT_create()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7291d74",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Utilities\n",
    "def list_images(img_dir: str):\n",
    "    exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\")\n",
    "    img_paths = []\n",
    "    for ext in exts:\n",
    "        img_paths.extend(glob.glob(os.path.join(img_dir, ext)))\n",
    "    img_paths = sorted(img_paths)\n",
    "    return img_paths\n",
    "\n",
    "def read_yolo_boxes(label_path: str, img_w: int, img_h: int):\n",
    "    boxes, labels = [], []\n",
    "    if not os.path.exists(label_path): return boxes, labels\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5: continue\n",
    "            cls = int(float(parts[0]))\n",
    "            xc, yc, w, h = map(float, parts[1:5])\n",
    "            bw, bh = w * img_w, h * img_h\n",
    "            x, y = (xc - w/2.0) * img_w, (yc - h/2.0) * img_h\n",
    "            x, y = int(np.clip(x, 0, img_w - 1)), int(np.clip(y, 0, img_h - 1))\n",
    "            bw, bh = int(np.clip(bw, 1, img_w - x)), int(np.clip(bh, 1, img_h - y))\n",
    "            boxes.append((x, y, bw, bh))\n",
    "            labels.append(cls)\n",
    "    return boxes, labels\n",
    "\n",
    "def iou_xywh(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    ax1, ay1, ax2, ay2 = x1, y1, x1 + w1 - 1, y1 + h1 - 1\n",
    "    bx1, by1, bx2, by2 = x2, y2, x2 + w2 - 1, y2 + h2 - 1\n",
    "    iw = max(0, min(ax2, bx2) - max(ax1, bx1) + 1)\n",
    "    ih = max(0, min(ay2, by2) - max(ay1, by1) + 1)\n",
    "    inter = iw * ih\n",
    "    if inter <= 0: return 0.0\n",
    "    area_a = w1 * h1\n",
    "    area_b = w2 * h2\n",
    "    return inter / float(area_a + area_b - inter + 1e-9)\n",
    "\n",
    "def nms_xywh(boxes, scores, iou_thr=DET_NMS_IOU_THR):\n",
    "    if len(boxes) == 0: return [], []\n",
    "    boxes = np.array(boxes, dtype=np.float32)\n",
    "    scores = np.array(scores, dtype=np.float32)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep_indices = []\n",
    "    while len(order) > 0:\n",
    "        i = order[0]\n",
    "        keep_indices.append(int(i))\n",
    "        if len(order) == 1: break\n",
    "        rest = order[1:]\n",
    "        i_box = boxes[i]\n",
    "        ious = []\n",
    "        for j in rest:\n",
    "            j_box = boxes[j]\n",
    "            ious.append(iou_xywh(tuple(i_box), tuple(j_box)))\n",
    "        ious = np.array(ious, dtype=np.float32)\n",
    "        remaining = rest[ious <= iou_thr]\n",
    "        order = remaining\n",
    "    final_boxes = [tuple(boxes[i].astype(int)) for i in keep_indices]\n",
    "    final_scores = [float(scores[i]) for i in keep_indices]\n",
    "    return final_boxes, final_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13661b13",
   "metadata": {},
   "source": [
    "# Classification Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Classification Module (12 Classes)\n",
    "\n",
    "#Extract HOG descriptor for an input image\n",
    "def clf_get_hog(img, cfg):\n",
    "    win_size = cfg['STD_SIZE']\n",
    "    block_size = (cfg['HOG_BLOCK'], cfg['HOG_BLOCK'])\n",
    "    block_stride = (cfg['HOG_STRIDE'], cfg['HOG_STRIDE'])\n",
    "    cell_size = (cfg['HOG_CELL'], cfg['HOG_CELL'])\n",
    "    if img.shape[:2] != win_size[::-1]:\n",
    "        img = cv2.resize(img, win_size)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    hog_desc = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, 9)\n",
    "    return hog_desc.compute(gray).flatten()\n",
    "\n",
    "#Compute HSV colour histogram:\n",
    "def clf_get_color(img, bins):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    chans = cv2.split(hsv)\n",
    "    hists = [cv2.calcHist([c],[0],None,[bins],[0,256]) for c in chans]\n",
    "    for h in hists: cv2.normalize(h, h)\n",
    "    return np.hstack([h.flatten() for h in hists])\n",
    "\n",
    "#Extract Dense SIFT\n",
    "def clf_get_dense_sift(imgs, step):\n",
    "    descs = []\n",
    "    for img in imgs:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        kps = [cv2.KeyPoint(x, y, step) for y in range(0, gray.shape[0], step) for x in range(0, gray.shape[1], step)]\n",
    "        _, d = sift.compute(gray, kps)\n",
    "        descs.append(d)\n",
    "    return descs\n",
    "\n",
    "#Build final feature vector\n",
    "def clf_create_features(imgs, vocab, cfg):\n",
    "    descs = clf_get_dense_sift(imgs, cfg['SIFT_STEP'])\n",
    "    k = vocab.n_clusters\n",
    "    bovw_feats = np.zeros((len(imgs), k), np.float32)\n",
    "    for i, d in enumerate(descs):\n",
    "        if d is not None:\n",
    "            words = vocab.predict(d)\n",
    "            hist, _ = np.histogram(words, bins=np.arange(k+1))\n",
    "            if hist.sum() > 0: hist = hist / np.linalg.norm(hist)\n",
    "            bovw_feats[i] = hist\n",
    "    other_feats = []\n",
    "    for im in imgs:\n",
    "        h = clf_get_hog(im, cfg)\n",
    "        c = clf_get_color(im, cfg['COLOR_BINS'])\n",
    "        other_feats.append(np.hstack((cfg['W_HOG']*h, cfg['W_COLOR']*c)))\n",
    "    return np.hstack((cfg['W_BOVW'] * bovw_feats, np.array(other_feats)))\n",
    "\n",
    "#Load training data and train the classifier\n",
    "def load_classifier_data_and_train(max_images=3000):\n",
    "    print(\"\\nClassifier Loading Training Data\")\n",
    "    files = os.listdir(TRAIN_LBL_DIR)\n",
    "    random.shuffle(files)\n",
    "    if max_images: files = files[:max_images]\n",
    "    \n",
    "    train_imgs, train_lbls = [], []\n",
    "    for f in tqdm(files, desc=\"Loading Train Crops\"):\n",
    "        if not f.endswith('.txt'): continue\n",
    "        img_path = os.path.join(TRAIN_IMG_DIR, os.path.splitext(f)[0] + '.jpg')\n",
    "        if not os.path.exists(img_path): continue\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h, w, _ = img.shape\n",
    "        with open(os.path.join(TRAIN_LBL_DIR, f)) as lf:\n",
    "            for line in lf:\n",
    "                try:\n",
    "                    cid, x, y, wn, hn = map(float, line.split())\n",
    "                    x1, y1 = int((x-wn/2)*w), int((y-hn/2)*h)\n",
    "                    x2, y2 = int((x+wn/2)*w), int((y+hn/2)*h)\n",
    "                    crop = img[max(0,y1):min(h,y2), max(0,x1):min(w,x2)]\n",
    "                    if crop.size > 0:\n",
    "                        train_imgs.append(cv2.resize(crop, CLF_CONFIG['STD_SIZE']))\n",
    "                        train_lbls.append(int(cid))\n",
    "                except: continue\n",
    "    print(f\"Loaded {len(train_imgs)} training crops.\")\n",
    "    \n",
    "    print(\"Training BoVW Voca\")\n",
    "    vocab = MiniBatchKMeans(n_clusters=CLF_CONFIG['K_VOCAB_SIZE'], batch_size=512, n_init=3, max_iter=100)\n",
    "    sample_imgs = train_imgs[:1000] if len(train_imgs) > 1000 else train_imgs\n",
    "    descs = clf_get_dense_sift(sample_imgs, CLF_CONFIG['SIFT_STEP'])\n",
    "    flat_descs = np.vstack([d for d in descs if d is not None])\n",
    "    vocab.fit(flat_descs)\n",
    "    \n",
    "    print(\"Training SVC\")\n",
    "    X_train = clf_create_features(train_imgs, vocab, CLF_CONFIG)\n",
    "    y_train = np.array(train_lbls)\n",
    "    clf_model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(C=CLF_CONFIG['C'], kernel=CLF_CONFIG['KERNEL'], class_weight='balanced', probability=True)\n",
    "    )\n",
    "    clf_model.fit(X_train, y_train)\n",
    "    return clf_model, vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33294103",
   "metadata": {},
   "source": [
    "# Detector module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de985174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Detector Module\n",
    "\n",
    "#Feature Extraction\n",
    "def crop_resize_gray(bgr: np.ndarray, box: Tuple[int, int, int, int], size: Tuple[int, int] = PATCH_SIZE):\n",
    "    x, y, w, h = box\n",
    "    H, W = bgr.shape[:2]\n",
    "    x0 = max(0, x); y0 = max(0, y)\n",
    "    x1 = min(W, x + w); y1 = min(H, y + h)\n",
    "    if x0 >= x1 or y0 >= y1: return None\n",
    "    crop = bgr[y0:y1, x0:x1]\n",
    "    if crop.size == 0: return None\n",
    "    crop_resized = cv2.resize(crop, (size[1], size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    gray = cv2.cvtColor(crop_resized, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def extract_hog_feature(gray: np.ndarray):\n",
    "    feat = hog(\n",
    "        gray,\n",
    "        orientations=HOG_ORIENTATIONS,\n",
    "        pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "        cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "        block_norm=HOG_BLOCK_NORM,\n",
    "        transform_sqrt=HOG_TRANSFORM_SQRT,\n",
    "        feature_vector=True\n",
    "    )\n",
    "    return feat.astype(np.float32)\n",
    "\n",
    "#Training Dataset ready\n",
    "def sample_background_boxes(H, W, gt_boxes, num_neg, neg_iou_thr=NEG_IOU_THR, max_attempts_factor=BG_MAX_ATTEMPTS_FACTOR):\n",
    "    boxes = []\n",
    "    if num_neg <= 0: return boxes\n",
    "    max_attempts = max_attempts_factor * num_neg\n",
    "    attempts = 0\n",
    "    while len(boxes) < num_neg and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        min_size = max(16, min(H, W) // 10)\n",
    "        max_size = max(min_size + 1, min(H, W) // 2)\n",
    "        bw = np.random.randint(min_size, max_size)\n",
    "        bh = np.random.randint(min_size, max_size)\n",
    "        if bw <= 0 or bh <= 0: continue\n",
    "        x = np.random.randint(0, max(1, W - bw + 1))\n",
    "        y = np.random.randint(0, max(1, H - bh + 1))\n",
    "        box = (x, y, bw, bh)\n",
    "        ious = [iou_xywh(box, g) for g in gt_boxes]\n",
    "        if len(ious) > 0 and max(ious) > neg_iou_thr: continue\n",
    "        boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "def build_binary_dataset_for_split(img_dir, lbl_dir, split_name=\"train\", max_images=None, max_pos_per_img=MAX_POS_PER_IMG, neg_pos_ratio=NEG_POS_RATIO, neg_iou_thr=NEG_IOU_THR):\n",
    "    img_paths = list_images(img_dir)\n",
    "    if max_images is not None: img_paths = img_paths[:max_images]\n",
    "    if len(img_paths) == 0: raise RuntimeError(f\"No images found in {img_dir}\")\n",
    "    X_list, y_list = [], []\n",
    "    total_pos, total_neg = 0, 0\n",
    "    for img_path in tqdm(img_paths, desc=f\"Build binary HOG dataset @ {split_name}\"):\n",
    "        bgr = cv2.imread(img_path)\n",
    "        if bgr is None: continue\n",
    "        H, W = bgr.shape[:2]\n",
    "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "        gt_boxes, gt_labels = read_yolo_boxes(label_path, W, H)\n",
    "        # Positive\n",
    "        pos_boxes = gt_boxes\n",
    "        if max_pos_per_img is not None and len(pos_boxes) > max_pos_per_img: pos_boxes = pos_boxes[:max_pos_per_img]\n",
    "        for box in pos_boxes:\n",
    "            gray = crop_resize_gray(bgr, box)\n",
    "            if gray is None: continue\n",
    "            feat = extract_hog_feature(gray)\n",
    "            X_list.append(feat)\n",
    "            y_list.append(INSECT_LABEL)\n",
    "            total_pos += 1\n",
    "        # Negative\n",
    "        if neg_pos_ratio > 0:\n",
    "            pos_count_for_neg = len(pos_boxes) if len(pos_boxes) > 0 else (max_pos_per_img or 10)\n",
    "            num_neg_desired = int(pos_count_for_neg * neg_pos_ratio)\n",
    "            bg_boxes = sample_background_boxes(H, W, gt_boxes, num_neg=num_neg_desired, neg_iou_thr=neg_iou_thr)\n",
    "            for box in bg_boxes:\n",
    "                gray_bg = crop_resize_gray(bgr, box)\n",
    "                if gray_bg is None: continue\n",
    "                feat_bg = extract_hog_feature(gray_bg)\n",
    "                X_list.append(feat_bg)\n",
    "                y_list.append(BACKGROUND_LABEL)\n",
    "                total_neg += 1\n",
    "    if len(X_list) == 0: raise RuntimeError(f\"No samples collected from {img_dir}.\")\n",
    "    X = np.vstack(X_list).astype(np.float32)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    print(f\"[INFO] {split_name} split: total sample = {len(y)}\")\n",
    "    print(f\"[INFO]   - Positive(Insect=1): {total_pos}\")\n",
    "    print(f\"[INFO]   - Negative(Background=0): {total_neg}\")\n",
    "    return X, y\n",
    "\n",
    "#Image Segmenatation\n",
    "def _to_colorspace(bgr, mode=\"LAB\"):\n",
    "    mode = mode.upper()\n",
    "    if mode == \"LAB\": return cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    elif mode == \"HSV\": return cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    else: raise ValueError(\"COLOR_SPACE must be 'LAB' or 'HSV'.\")\n",
    "\n",
    "def _border_stats(colimg, border_px):\n",
    "    H, W = colimg.shape[:2]\n",
    "    m = np.zeros((H, W), np.uint8)\n",
    "    m[:border_px,:] = 1; m[-border_px:,:] = 1; m[:,:border_px] = 1; m[:,-border_px:] = 1\n",
    "    samples = colimg[m>0].reshape(-1, colimg.shape[2])\n",
    "    mu  = np.median(samples, axis=0).astype(np.float32)\n",
    "    cov = np.cov(samples.T).astype(np.float32) if len(samples)>=10 else np.eye(colimg.shape[2], dtype=np.float32)\n",
    "    return mu, cov\n",
    "\n",
    "def _mahalanobis(X, mu, cov):\n",
    "    C = cov.shape[0]\n",
    "    inv = np.linalg.inv(cov + 1e-6*np.eye(C, dtype=np.float32))\n",
    "    d = (X - mu).astype(np.float32)\n",
    "    return np.sqrt(np.einsum('...i,ij,...j->...', d, inv, d)).astype(np.float32)\n",
    "\n",
    "def _grad_mag(gray):\n",
    "    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    mag = cv2.magnitude(gx, gy)\n",
    "    mag = mag / (mag.max() + 1e-6)\n",
    "    return mag.astype(np.float32)\n",
    "\n",
    "def _norm01(x):\n",
    "    x = x.astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    return np.zeros_like(x) if mx-mn < 1e-6 else (x-mn)/(mx-mn)\n",
    "\n",
    "def make_fg_mask_simple(bgr):\n",
    "    H, W = bgr.shape[:2]\n",
    "    blur = cv2.GaussianBlur(bgr, (GAUSS_KSIZE, GAUSS_KSIZE), 0)\n",
    "    col = _to_colorspace(blur, COLOR_SPACE)\n",
    "    mu, cov = _border_stats(col, BORDER_PX)\n",
    "    dist = _mahalanobis(col.reshape(-1, col.shape[2]), mu, cov).reshape(H, W)\n",
    "    color_score = _norm01(dist)\n",
    "    gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
    "    edge_score = _grad_mag(gray)\n",
    "    fused = COLOR_WEIGHT*color_score + EDGE_WEIGHT*edge_score\n",
    "    fused = _norm01(fused)\n",
    "    if OTSU_BIAS != 0.0: fused = np.clip(fused - OTSU_BIAS, 0, 1)\n",
    "    fused_u8 = (fused*255).astype(np.uint8)\n",
    "    _, mask = cv2.threshold(fused_u8, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=int(CC_CONNECT))\n",
    "    out = np.zeros_like(mask)\n",
    "    img_area = H*W\n",
    "    for i in range(1, num):\n",
    "        x,y,w,h,area = stats[i]\n",
    "        if area < AREA_MIN_RATIO*img_area or area > AREA_MAX_RATIO*img_area: continue\n",
    "        out[labels==i] = 255\n",
    "    return out\n",
    "\n",
    "#Regoin Proposal Logic\n",
    "def propose_boxes_from_mask(mask, min_area_ratio=0.001, max_area_ratio=0.90, pad=4, connectivity=8, merge=True, merge_iou=0.30):\n",
    "    if mask is None or mask.size == 0: return []\n",
    "    if mask.dtype != np.uint8: binm = (mask > 0).astype(np.uint8)\n",
    "    else: binm = (mask > 0).astype(np.uint8)\n",
    "    H, W = binm.shape[:2]\n",
    "    img_area = H * W\n",
    "    if img_area == 0: return []\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(binm, connectivity=int(connectivity))\n",
    "    boxes = []\n",
    "    for i in range(1, num):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area < min_area_ratio * img_area or area > max_area_ratio * img_area: continue\n",
    "        x0 = max(0, x - pad); y0 = max(0, y - pad)\n",
    "        x1 = min(W - 1, x + w + pad - 1); y1 = min(H - 1, y + h + pad - 1)\n",
    "        boxes.append((int(x0), int(y0), int(max(1, x1 - x0 + 1)), int(max(1, y1 - y0 + 1))))\n",
    "    if not merge or len(boxes) <= 1:\n",
    "        boxes.sort(key=lambda b: b[2]*b[3], reverse=True)\n",
    "        return boxes\n",
    "    def _xywh_to_xyxy(b): return (b[0], b[1], b[0] + b[2] - 1, b[1] + b[3] - 1)\n",
    "    def _xyxy_to_xywh(b): return (b[0], b[1], b[2] - b[0] + 1, b[3] - b[1] + 1)\n",
    "    def _iou(a, b):\n",
    "        iw = max(0, min(a[2], b[2]) - max(a[0], b[0]) + 1)\n",
    "        ih = max(0, min(a[3], b[3]) - max(a[1], b[1]) + 1)\n",
    "        inter = iw * ih\n",
    "        if inter <= 0: return 0.0\n",
    "        area_a = (a[2]-a[0]+1)*(a[3]-a[1]+1)\n",
    "        area_b = (b[2]-b[0]+1)*(b[3]-b[1]+1)\n",
    "        return inter / float(area_a + area_b - inter + 1e-9)\n",
    "    xyxy = [_xywh_to_xyxy(b) for b in boxes]\n",
    "    changed = True\n",
    "    while changed and len(xyxy) > 1:\n",
    "        changed = False\n",
    "        new_xyxy = []\n",
    "        used = [False] * len(xyxy)\n",
    "        for i in range(len(xyxy)):\n",
    "            if used[i]: continue\n",
    "            merged = xyxy[i]\n",
    "            used[i] = True\n",
    "            for j in range(i + 1, len(xyxy)):\n",
    "                if used[j]: continue\n",
    "                if _iou(merged, xyxy[j]) >= merge_iou:\n",
    "                    x1 = min(merged[0], xyxy[j][0]); y1 = min(merged[1], xyxy[j][1])\n",
    "                    x2 = max(merged[2], xyxy[j][2]); y2 = max(merged[3], xyxy[j][3])\n",
    "                    merged = (x1, y1, x2, y2)\n",
    "                    used[j] = True\n",
    "                    changed = True\n",
    "            new_xyxy.append(merged)\n",
    "        xyxy = new_xyxy\n",
    "    merged_boxes = [_xyxy_to_xywh(b) for b in xyxy]\n",
    "    merged_boxes.sort(key=lambda b: b[2]*b[3], reverse=True)\n",
    "    return merged_boxes\n",
    "\n",
    "def get_candidate_boxes(bgr, use_preproc=True):\n",
    "    H, W = bgr.shape[:2]\n",
    "    all_boxes = []\n",
    "    if use_preproc:\n",
    "        fg_mask = make_fg_mask_simple(bgr)\n",
    "        boxes_fg = propose_boxes_from_mask(fg_mask, min_area_ratio=0.001, max_area_ratio=0.9, pad=4, connectivity=8, merge=True, merge_iou=0.30)\n",
    "        all_boxes.extend(boxes_fg)\n",
    "    all_boxes = list({(x, y, w, h) for (x, y, w, h) in all_boxes})\n",
    "    return all_boxes\n",
    "\n",
    "#Score candidate boxes with SVM,and NMS\n",
    "def compute_scores_for_boxes(bgr, boxes, scaler, svm):\n",
    "    feats = []\n",
    "    valid_boxes = []\n",
    "    for box in boxes:\n",
    "        gray = crop_resize_gray(bgr, box, size=PATCH_SIZE)\n",
    "        if gray is None: continue\n",
    "        feat = extract_hog_feature(gray)\n",
    "        feats.append(feat)\n",
    "        valid_boxes.append(box)\n",
    "    if len(feats) == 0: return [], np.array([])\n",
    "    X = np.vstack(feats).astype(np.float32)\n",
    "    X_std = scaler.transform(X)\n",
    "    scores = svm.decision_function(X_std)\n",
    "    return valid_boxes, scores\n",
    "\n",
    "def filter_boxes_by_score(boxes, scores, score_thr):\n",
    "    if len(boxes) == 0 or scores.size == 0: return [], np.array([])\n",
    "    keep_idx = np.where(scores >= score_thr)[0]\n",
    "    if len(keep_idx) == 0: return [], np.array([])\n",
    "    boxes_pos = [boxes[i] for i in keep_idx]\n",
    "    scores_pos = scores[keep_idx]\n",
    "    return boxes_pos, scores_pos\n",
    "\n",
    "def detect_in_image(bgr, scaler, svm, use_preproc=True):\n",
    "    all_boxes = get_candidate_boxes(bgr, use_preproc=use_preproc)\n",
    "    if len(all_boxes) == 0: return [], np.array([])\n",
    "    valid_boxes, scores = compute_scores_for_boxes(bgr, all_boxes, scaler, svm)\n",
    "    if len(valid_boxes) == 0: return [], np.array([])\n",
    "    boxes_pos, scores_pos = filter_boxes_by_score(valid_boxes, scores, DET_SCORE_THRESH)\n",
    "    if len(boxes_pos) == 0: return [], np.array([])\n",
    "    final_boxes, final_scores = nms_xywh(boxes_pos, scores_pos, iou_thr=DET_NMS_IOU_THR)\n",
    "    return final_boxes, final_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31974c",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN EXECUTION (Train)\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 1. Train Classifier (12 Classes)\n",
    "    print(\"\\n Training Multi Class Classifier\")\n",
    "    clf_model, vocab = load_classifier_data_and_train(max_images=TRAIN_MAX_IMAGES)\n",
    "    \n",
    "    # 2. Train Detector (Binary)\n",
    "    print(\"\\nTraining Binary Detector\")\n",
    "    # 2-1. Train set\n",
    "    X_train_det, y_train_det = build_binary_dataset_for_split(\n",
    "        TRAIN_IMG_DIR, TRAIN_LBL_DIR, split_name=\"train\",\n",
    "        max_images=TRAIN_MAX_IMAGES, max_pos_per_img=MAX_POS_PER_IMG,\n",
    "        neg_pos_ratio=NEG_POS_RATIO, neg_iou_thr=NEG_IOU_THR\n",
    "    )\n",
    "    # 2-2. Valid set\n",
    "    X_val_det, y_val_det = build_binary_dataset_for_split(\n",
    "        VAL_IMG_DIR, VAL_LBL_DIR, split_name=\"valid\",\n",
    "        max_images=VAL_MAX_IMAGES, max_pos_per_img=MAX_POS_PER_IMG,\n",
    "        neg_pos_ratio=NEG_POS_RATIO, neg_iou_thr=NEG_IOU_THR\n",
    "    )\n",
    "    # 2-3. Scaler & SVM\n",
    "    print(\"\\nTraining Detector SVM\")\n",
    "    det_scaler = StandardScaler()\n",
    "    X_train_std = det_scaler.fit_transform(X_train_det)\n",
    "    det_model = LinearSVC(\n",
    "        C=SVM_C, class_weight=SVM_CLASS_WEIGHT,\n",
    "        max_iter=SVM_MAX_ITER, random_state=SVM_RANDOM_STATE\n",
    "    )\n",
    "    det_model.fit(X_train_std, y_train_det)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c8c81",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d67c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#Compute mAP@IoU\n",
    "def compute_map(all_preds, all_gts, num_classes, iou_thr=0.5):\n",
    "    aps = []\n",
    "\n",
    "    for cid in range(num_classes):\n",
    "        preds_c = [p for p in all_preds if p['class_id'] == cid]\n",
    "        gts_c   = [g for g in all_gts   if g['class_id'] == cid]\n",
    "\n",
    "        if len(gts_c) == 0:\n",
    "            continue\n",
    "\n",
    "        preds_c = sorted(preds_c, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        tp = np.zeros(len(preds_c), dtype=np.float32)\n",
    "        fp = np.zeros(len(preds_c), dtype=np.float32)\n",
    "\n",
    "        gt_used = [False] * len(gts_c)\n",
    "\n",
    "        for i, pred in enumerate(preds_c):\n",
    "            best_iou = 0.0\n",
    "            best_gt_idx = -1\n",
    "            for j, gt in enumerate(gts_c):\n",
    "                if pred['img_id'] != gt['img_id']:\n",
    "                    continue\n",
    "                iou = iou_xywh(pred['box'], gt['box'])\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = j\n",
    "\n",
    "            if best_iou >= iou_thr and best_gt_idx >= 0 and not gt_used[best_gt_idx]:\n",
    "                tp[i] = 1.0\n",
    "                gt_used[best_gt_idx] = True\n",
    "            else:\n",
    "                fp[i] = 1.0\n",
    "\n",
    "        tp_cum = np.cumsum(tp)\n",
    "        fp_cum = np.cumsum(fp)\n",
    "\n",
    "        recalls = tp_cum / (len(gts_c) + 1e-9)\n",
    "        precisions = tp_cum / (tp_cum + fp_cum + 1e-9)\n",
    "\n",
    "        if len(precisions) == 0:\n",
    "            aps.append(0.0)\n",
    "            continue\n",
    "\n",
    "        mpre = np.concatenate(([0.0], precisions, [0.0]))\n",
    "        mrec = np.concatenate(([0.0], recalls,    [1.0]))\n",
    "\n",
    "        for k in range(len(mpre) - 2, -1, -1):\n",
    "            mpre[k] = max(mpre[k], mpre[k + 1])\n",
    "\n",
    "        idx = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "        ap = np.sum((mrec[idx + 1] - mrec[idx]) * mpre[idx + 1])\n",
    "        aps.append(ap)\n",
    "\n",
    "    if len(aps) == 0:\n",
    "        return 0.0\n",
    "    return float(np.mean(aps))\n",
    "\n",
    "#Full-system evaluation: runs detection -> classification -> metric calculation\n",
    "def evaluate_full_system(\n",
    "    clf_model,\n",
    "    vocab,\n",
    "    det_model,\n",
    "    det_scaler,\n",
    "    img_dir,\n",
    "    lbl_dir,\n",
    "    max_images=None,\n",
    "    iou_thr=0.5\n",
    "):\n",
    "    img_paths = list_images(img_dir)\n",
    "    if max_images is not None:\n",
    "        img_paths = img_paths[:max_images]\n",
    "\n",
    "    class_stats = defaultdict(lambda: {'TP': 0, 'FP': 0, 'n_gt': 0})\n",
    "\n",
    "    all_preds = []  \n",
    "    all_gts   = []  \n",
    "\n",
    "    detection_records = [] \n",
    "\n",
    "    for img_path in tqdm(img_paths, desc=\"Eval Full System\"):\n",
    "        img_id = os.path.basename(img_path)\n",
    "        bgr = cv2.imread(img_path)\n",
    "        if bgr is None:\n",
    "            continue\n",
    "        H, W = bgr.shape[:2]\n",
    "\n",
    "        label_path = os.path.join(lbl_dir, os.path.splitext(img_id)[0] + \".txt\")\n",
    "        gt_boxes, gt_labels = read_yolo_boxes(label_path, W, H)\n",
    "\n",
    "        image_gt_by_class = defaultdict(list)\n",
    "        for gb, gl in zip(gt_boxes, gt_labels):\n",
    "            all_gts.append({'img_id': img_id, 'box': gb, 'class_id': gl})\n",
    "            image_gt_by_class[gl].append(gb)\n",
    "            class_stats[gl]['n_gt'] += 1\n",
    "\n",
    "        # Detection\n",
    "        final_boxes, final_scores = detect_in_image(\n",
    "            bgr,\n",
    "            det_scaler,\n",
    "            det_model,\n",
    "            use_preproc=True\n",
    "        )\n",
    "\n",
    "        if len(final_boxes) == 0:\n",
    "            continue\n",
    "\n",
    "        rois = []\n",
    "        for box in final_boxes:\n",
    "            x, y, w, h = box\n",
    "            crop = bgr[y:y+h, x:x+w]\n",
    "            if crop.size > 0:\n",
    "                roi = cv2.resize(crop, CLF_CONFIG['STD_SIZE'])\n",
    "            else:\n",
    "                roi = np.zeros((CLF_CONFIG['STD_SIZE'][0],\n",
    "                                CLF_CONFIG['STD_SIZE'][1], 3), dtype=np.uint8)\n",
    "            rois.append(roi)\n",
    "\n",
    "        X_clf = clf_create_features(rois, vocab, CLF_CONFIG)\n",
    "        cls_probs = clf_model.predict_proba(X_clf)\n",
    "        pred_classes = np.argmax(cls_probs, axis=1)\n",
    "        pred_scores  = np.max(cls_probs, axis=1)\n",
    "\n",
    "        for cid in range(len(CLASS_NAMES)):\n",
    "            preds_c = []\n",
    "            gts_c   = image_gt_by_class[cid]\n",
    "\n",
    "            for box, pcls, pscore in zip(final_boxes, pred_classes, pred_scores):\n",
    "                if pcls == cid:\n",
    "                    preds_c.append((box, pscore))\n",
    "\n",
    "            if len(gts_c) == 0 and len(preds_c) == 0:\n",
    "                continue\n",
    "\n",
    "            used_gt = [False] * len(gts_c)\n",
    "\n",
    "            preds_c_sorted = sorted(preds_c, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            for (pb, pscore) in preds_c_sorted:\n",
    "                best_iou = 0.0\n",
    "                best_gt_idx = -1\n",
    "                for gi, gb in enumerate(gts_c):\n",
    "                    if used_gt[gi]:\n",
    "                        continue\n",
    "                    iou = iou_xywh(pb, gb)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = gi\n",
    "\n",
    "                if best_iou >= iou_thr and best_gt_idx >= 0:\n",
    "                    class_stats[cid]['TP'] += 1\n",
    "                    used_gt[best_gt_idx] = True\n",
    "                else:\n",
    "                    class_stats[cid]['FP'] += 1\n",
    "\n",
    "        for box, pcls, pscore in zip(final_boxes, pred_classes, pred_scores):\n",
    "            all_preds.append({\n",
    "                'img_id': img_id,\n",
    "                'box': box,\n",
    "                'class_id': int(pcls),\n",
    "                'score': float(pscore)\n",
    "            })\n",
    "\n",
    "            best_iou = 0.0\n",
    "            best_gt_cls = None\n",
    "            for gb, gl in zip(gt_boxes, gt_labels):\n",
    "                iou = iou_xywh(box, gb)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_cls = gl\n",
    "\n",
    "            is_match = best_iou >= iou_thr and best_gt_cls is not None\n",
    "            is_correct_class = (is_match and (best_gt_cls == pcls))\n",
    "\n",
    "            detection_records.append({\n",
    "                'img_path': img_path,\n",
    "                'img_id': img_id,\n",
    "                'box': box,\n",
    "                'pred_cls': int(pcls),\n",
    "                'pred_score': float(pscore),\n",
    "                'best_iou': float(best_iou),\n",
    "                'gt_cls': int(best_gt_cls) if best_gt_cls is not None else None,\n",
    "                'is_match': bool(is_match),\n",
    "                'is_correct_class': bool(is_correct_class)\n",
    "            })\n",
    "\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"{'Class':<15} | {'Prec.':<8} | {'Recall':<8} | {'F1':<8} | {'TP':<5} | {'FP':<5} | {'GT':<5}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    macro_prec = 0.0\n",
    "    macro_rec  = 0.0\n",
    "    macro_f1   = 0.0\n",
    "    valid_classes = 0\n",
    "\n",
    "    for cid in range(len(CLASS_NAMES)):\n",
    "        stats = class_stats[cid]\n",
    "        tp = stats['TP']\n",
    "        fp = stats['FP']\n",
    "        gt = stats['n_gt']\n",
    "        fn = gt - tp\n",
    "\n",
    "        prec = tp / (tp + fp + 1e-9)\n",
    "        rec  = tp / (tp + fn + 1e-9)\n",
    "        f1   = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "\n",
    "        if gt > 0:\n",
    "            macro_prec += prec\n",
    "            macro_rec  += rec\n",
    "            macro_f1   += f1\n",
    "            valid_classes += 1\n",
    "\n",
    "        print(f\"{CLASS_NAMES[cid]:<15} | {prec:.4f}   | {rec:.4f}   | {f1:.4f}   | {tp:<5} | {fp:<5} | {gt:<5}\")\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    if valid_classes > 0:\n",
    "        print(f\"{'Macro Avg':<15} | {macro_prec/valid_classes:.4f}   | {macro_rec/valid_classes:.4f}   | {macro_f1/valid_classes:.4f}   | -     | -     | -\")\n",
    "\n",
    "    mAP = compute_map(all_preds, all_gts, num_classes=len(CLASS_NAMES), iou_thr=iou_thr)\n",
    "    print(f\"\\n>>> Final mAP@{iou_thr:.2f}: {mAP:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'class_stats': class_stats,\n",
    "        'mAP': mAP,\n",
    "        'detection_records': detection_records\n",
    "    }\n",
    "\n",
    "def visualize_detections(\n",
    "    detection_records,\n",
    "    num_good=3,\n",
    "    num_bad=3,\n",
    "    iou_thr=0.5,\n",
    "    score_thr=0.0,\n",
    "    random_seed=0\n",
    "):\n",
    "    import random\n",
    "    random.seed(random_seed)\n",
    "    good = [\n",
    "        rec for rec in detection_records\n",
    "        if rec['pred_score'] >= score_thr\n",
    "        and rec['is_correct_class']\n",
    "        and rec['best_iou'] >= iou_thr\n",
    "    ]\n",
    "\n",
    "    bad = [\n",
    "        rec for rec in detection_records\n",
    "        if rec['pred_score'] >= score_thr\n",
    "        and (not rec['is_correct_class'])\n",
    "    ]\n",
    "\n",
    "    print(f\"[INFO] Available good(TP) samples: {len(good)}\")\n",
    "    print(f\"[INFO] Available bad(FP/misclass) samples: {len(bad)}\")\n",
    "\n",
    "    good_samples = random.sample(good, min(num_good, len(good))) if len(good) > 0 else []\n",
    "    bad_samples  = random.sample(bad,  min(num_bad,  len(bad)))  if len(bad)  > 0 else []\n",
    "\n",
    "    def _show_samples(samples, title_prefix, box_color, max_cols=3):\n",
    "        if not samples:\n",
    "            print(f\"[WARN] No samples to show for {title_prefix}\")\n",
    "            return\n",
    "\n",
    "        n = len(samples)\n",
    "        ncols = min(max_cols, n)\n",
    "        nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=(4*ncols, 4*nrows))\n",
    "        if nrows == 1 and ncols == 1:\n",
    "            axes = [[axes]]\n",
    "        elif nrows == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for idx, rec in enumerate(samples):\n",
    "            r = idx // ncols\n",
    "            c = idx % ncols\n",
    "            ax = axes[r][c]\n",
    "\n",
    "            img = cv2.imread(rec['img_path'])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            x, y, w, h = rec['box']\n",
    "            rect = patches.Rectangle(\n",
    "                (x, y), w, h,\n",
    "                linewidth=2, edgecolor=box_color, facecolor='none'\n",
    "            )\n",
    "\n",
    "            ax.imshow(img)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            pred_name = CLASS_NAMES[rec['pred_cls']]\n",
    "            if rec['gt_cls'] is not None:\n",
    "                gt_name = CLASS_NAMES[rec['gt_cls']]\n",
    "            else:\n",
    "                gt_name = \"None\"\n",
    "\n",
    "            ax.set_title(\n",
    "                f\"{title_prefix}\\n\"\n",
    "                f\"Pred: {pred_name} ({rec['pred_score']:.2f})\\n\"\n",
    "                f\"GT: {gt_name}, IoU={rec['best_iou']:.2f}\",\n",
    "                fontsize=9\n",
    "            )\n",
    "            ax.axis('off')\n",
    "\n",
    "        for idx in range(n, nrows*ncols):\n",
    "            r = idx // ncols\n",
    "            c = idx % ncols\n",
    "            axes[r][c].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    _show_samples(good_samples, title_prefix=\"True Positive\", box_color='g')\n",
    "\n",
    "    _show_samples(bad_samples, title_prefix=\"False Positive / Misclassified\", box_color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679358a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_full_system(\n",
    "    clf_model=clf_model,\n",
    "    vocab=vocab,\n",
    "    det_model=det_model,\n",
    "    det_scaler=det_scaler,\n",
    "    img_dir=TEST_IMG_DIR,\n",
    "    lbl_dir=TEST_LBL_DIR,\n",
    "    max_images=None,   \n",
    "    iou_thr=0.5\n",
    ")\n",
    "\n",
    "detection_records = results['detection_records']\n",
    "\n",
    "visualize_detections(\n",
    "    detection_records,\n",
    "    num_good=3,   \n",
    "    num_bad=3,    \n",
    "    iou_thr=0.5,\n",
    "    score_thr=0.3,   \n",
    "    random_seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b34670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (COMP9517)",
   "language": "python",
   "name": "comp9517"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
