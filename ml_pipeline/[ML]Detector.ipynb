{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3870c442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, time, random, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import pyramid_gaussian \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported\")\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train', 'images')\n",
    "TRAIN_LBL_DIR = os.path.join(DATA_DIR, 'train', 'labels')\n",
    "VAL_IMG_DIR = os.path.join(DATA_DIR, 'valid', 'images')\n",
    "VAL_LBL_DIR = os.path.join(DATA_DIR, 'valid', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "216b66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# [Simple FG Mask] Color + Edge only (No texture, No morphology)\n",
    "# ============================\n",
    "\n",
    "import numpy as np, cv2\n",
    "\n",
    "# ---- íŒŒë¼ë¯¸í„° (ê°€ë³ê²Œ ì‹œì‘) ----\n",
    "BORDER_PX      = 13     # í…Œë‘ë¦¬ í­(px) - ë°°ê²½ í‘œë³¸ ì¶”ì¶œìš©\n",
    "COLOR_SPACE    = \"LAB\"  # \"LAB\" ê¶Œì¥ (HSVë„ ê°€ëŠ¥)\n",
    "COLOR_WEIGHT   = 1.6    # ìƒ‰ ì ìˆ˜ ê°€ì¤‘ì¹˜ (â†‘ ì „ê²½ì„ ìƒ‰ì°¨ ìœ„ì£¼ë¡œ)\n",
    "EDGE_WEIGHT    = 2.75   # ì—ì§€ ì ìˆ˜ ê°€ì¤‘ì¹˜ (â†‘ ìœ¤ê³½ ìœ„ì£¼ë¡œ)\n",
    "GAUSS_KSIZE    = 5      # ì‚¬ì „ ë¸”ëŸ¬(í™€ìˆ˜)\n",
    "CC_CONNECT     = 8      # ì—°ê²°ì„±(4/8)\n",
    "AREA_MIN_RATIO = 0.03  # ì—°ê²°ìš”ì†Œ ìµœì†Œ ë©´ì (ì´ë¯¸ì§€ ëŒ€ë¹„) â€” ì¡ì  ì œê±°\n",
    "AREA_MAX_RATIO = 0.45    # ì—°ê²°ìš”ì†Œ ìµœëŒ€ ë©´ì  â€” ë°°ê²½ ë©ì–´ë¦¬ ì»·\n",
    "OTSU_BIAS      = 0.00   # Otsu ì „ì— fusedì—ì„œ ë¹¼ëŠ” ë°”ì´ì–´ìŠ¤(0~0.2 ì‹œë„)\n",
    "\n",
    "\n",
    "def _to_colorspace(bgr, mode=\"LAB\"):\n",
    "    mode = mode.upper()\n",
    "    if mode == \"LAB\":\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    elif mode == \"HSV\":\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"COLOR_SPACE must be 'LAB' or 'HSV'.\")\n",
    "\n",
    "def _border_stats(colimg, border_px):\n",
    "    H, W = colimg.shape[:2]\n",
    "    m = np.zeros((H, W), np.uint8)\n",
    "    m[:border_px,:] = 1; m[-border_px:,:] = 1; m[:,:border_px] = 1; m[:,-border_px:] = 1\n",
    "    samples = colimg[m>0].reshape(-1, colimg.shape[2])\n",
    "    mu  = np.median(samples, axis=0).astype(np.float32)\n",
    "    cov = np.cov(samples.T).astype(np.float32) if len(samples)>=10 else np.eye(colimg.shape[2], dtype=np.float32)\n",
    "    return mu, cov\n",
    "\n",
    "def _mahalanobis(X, mu, cov):\n",
    "    C = cov.shape[0]\n",
    "    inv = np.linalg.inv(cov + 1e-6*np.eye(C, dtype=np.float32))\n",
    "    d = (X - mu).astype(np.float32)\n",
    "    return np.sqrt(np.einsum('...i,ij,...j->...', d, inv, d)).astype(np.float32)\n",
    "\n",
    "def _grad_mag(gray):\n",
    "    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    mag = cv2.magnitude(gx, gy)\n",
    "    mag = mag / (mag.max() + 1e-6)\n",
    "    return mag.astype(np.float32)\n",
    "\n",
    "def _norm01(x):\n",
    "    x = x.astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    return np.zeros_like(x) if mx-mn < 1e-6 else (x-mn)/(mx-mn)\n",
    "\n",
    "def make_fg_mask_simple(bgr):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤ì²˜/ëª¨í´ë¡œì§€ ì—†ì´:\n",
    "    - í…Œë‘ë¦¬ ë°°ê²½ í†µê³„ë¡œ Mahalanobis ìƒ‰ ê±°ë¦¬ + Sobel ì—ì§€ â†’ ì ìˆ˜ ê²°í•© â†’ Otsu\n",
    "    - ì‘ì€/ë„ˆë¬´ í° ì—°ê²°ìš”ì†Œë§Œ ë©´ì ìœ¼ë¡œ í•„í„°ë§\n",
    "    \"\"\"\n",
    "    H, W = bgr.shape[:2]\n",
    "    blur = cv2.GaussianBlur(bgr, (GAUSS_KSIZE, GAUSS_KSIZE), 0)\n",
    "\n",
    "    col = _to_colorspace(blur, COLOR_SPACE)\n",
    "    mu, cov = _border_stats(col, BORDER_PX)\n",
    "\n",
    "    dist = _mahalanobis(col.reshape(-1, col.shape[2]), mu, cov).reshape(H, W)\n",
    "    color_score = _norm01(dist)\n",
    "\n",
    "    gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
    "    edge_score = _grad_mag(gray)\n",
    "\n",
    "    fused = COLOR_WEIGHT*color_score + EDGE_WEIGHT*edge_score\n",
    "    fused = _norm01(fused)\n",
    "    if OTSU_BIAS != 0.0:\n",
    "        fused = np.clip(fused - OTSU_BIAS, 0, 1)\n",
    "\n",
    "    fused_u8 = (fused*255).astype(np.uint8)\n",
    "    _, mask = cv2.threshold(fused_u8, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    # í˜•íƒœí•™ ì—†ì´ â†’ ë©´ì  ê¸°ë°˜ ì—°ê²°ìš”ì†Œ í•„í„°ë§Œ\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=int(CC_CONNECT))\n",
    "    out = np.zeros_like(mask)\n",
    "    img_area = H*W\n",
    "    for i in range(1, num):\n",
    "        x,y,w,h,area = stats[i]\n",
    "        if area < AREA_MIN_RATIO*img_area or area > AREA_MAX_RATIO*img_area:\n",
    "            continue\n",
    "        out[labels==i] = 255\n",
    "    return out\n",
    "\n",
    "def propose_boxes_from_mask(\n",
    "    mask,\n",
    "    min_area_ratio=0.001,   # ì´ë¯¸ì§€ ëŒ€ë¹„ ìµœì†Œ ë©´ì (ë…¸ì´ì¦ˆ ì»·)\n",
    "    max_area_ratio=0.90,    # ì´ë¯¸ì§€ ëŒ€ë¹„ ìµœëŒ€ ë©´ì (ë°°ê²½ í° ë©ì–´ë¦¬ ì»·)\n",
    "    pad=4,                  # ë°•ìŠ¤ íŒ¨ë”©(px)\n",
    "    connectivity=8,         # ì—°ê²°ì„±(4 ë˜ëŠ” 8)\n",
    "    merge=True,             # ê²¹ì¹œ ë°•ìŠ¤ ë³‘í•© ì—¬ë¶€\n",
    "    merge_iou=0.30          # ë³‘í•© ì„ê³„ IoU\n",
    "):\n",
    "    \"\"\"\n",
    "    ì „ê²½ ë§ˆìŠ¤í¬(0/255) â†’ í›„ë³´ ë°•ìŠ¤ ëª©ë¡ [(x,y,w,h), ...] ìƒì„±\n",
    "    - ì—°ê²°ìš”ì†Œ ê¸°ë°˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ\n",
    "    - ë©´ì  ë¹„ìœ¨ë¡œ 1ì°¨ í•„í„°\n",
    "    - íŒ¨ë”© ë¶€ì—¬ í›„ ì´ë¯¸ì§€ ê²½ê³„ë¡œ í´ë¦½\n",
    "    - (ì˜µì…˜) IoU ê¸°ì¤€ìœ¼ë¡œ ë°•ìŠ¤ ë³‘í•©\n",
    "    \"\"\"\n",
    "    if mask is None or mask.size == 0:\n",
    "        return []\n",
    "\n",
    "    # ë§ˆìŠ¤í¬ ì´ì§„í™” ë³´ì •(0/255 ë³´ì¥)\n",
    "    if mask.dtype != np.uint8:\n",
    "        binm = (mask > 0).astype(np.uint8)\n",
    "    else:\n",
    "        binm = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    H, W = binm.shape[:2]\n",
    "    img_area = H * W\n",
    "    if img_area == 0:\n",
    "        return []\n",
    "\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(binm, connectivity=int(connectivity))\n",
    "    boxes = []\n",
    "    for i in range(1, num):  # 0ì€ ë°°ê²½\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area < min_area_ratio * img_area or area > max_area_ratio * img_area:\n",
    "            continue\n",
    "\n",
    "        # íŒ¨ë”©\n",
    "        x0 = max(0, x - pad)\n",
    "        y0 = max(0, y - pad)\n",
    "        x1 = min(W - 1, x + w + pad - 1)\n",
    "        y1 = min(H - 1, y + h + pad - 1)\n",
    "\n",
    "        xx, yy = int(x0), int(y0)\n",
    "        ww, hh = int(max(1, x1 - x0 + 1)), int(max(1, y1 - y0 + 1))\n",
    "        boxes.append((xx, yy, ww, hh))\n",
    "\n",
    "    if not merge or len(boxes) <= 1:\n",
    "        boxes.sort(key=lambda b: b[2]*b[3], reverse=True)\n",
    "        return boxes\n",
    "\n",
    "    # ---------------------------\n",
    "    # ê°„ë‹¨ ë³‘í•©(ë†’ì€ IoU ë°•ìŠ¤ í•©ì¹˜ê¸°)\n",
    "    # ---------------------------\n",
    "    def _xywh_to_xyxy(b):\n",
    "        x, y, w, h = b\n",
    "        return (x, y, x + w - 1, y + h - 1)\n",
    "\n",
    "    def _xyxy_to_xywh(b):\n",
    "        x1, y1, x2, y2 = b\n",
    "        return (x1, y1, x2 - x1 + 1, y2 - y1 + 1)\n",
    "\n",
    "    def _iou(a, b):\n",
    "        ax1, ay1, ax2, ay2 = a\n",
    "        bx1, by1, bx2, by2 = b\n",
    "        iw = max(0, min(ax2, bx2) - max(ax1, bx1) + 1)\n",
    "        ih = max(0, min(ay2, by2) - max(ay1, by1) + 1)\n",
    "        inter = iw * ih\n",
    "        if inter <= 0:\n",
    "            return 0.0\n",
    "        area_a = (ax2 - ax1 + 1) * (ay2 - ay1 + 1)\n",
    "        area_b = (bx2 - bx1 + 1) * (by2 - by1 + 1)\n",
    "        return inter / float(area_a + area_b - inter + 1e-9)\n",
    "\n",
    "    xyxy = [_xywh_to_xyxy(b) for b in boxes]\n",
    "    changed = True\n",
    "    while changed and len(xyxy) > 1:\n",
    "        changed = False\n",
    "        new_xyxy = []\n",
    "        used = [False] * len(xyxy)\n",
    "\n",
    "        for i in range(len(xyxy)):\n",
    "            if used[i]:\n",
    "                continue\n",
    "            merged = xyxy[i]\n",
    "            used[i] = True\n",
    "            for j in range(i + 1, len(xyxy)):\n",
    "                if used[j]:\n",
    "                    continue\n",
    "                if _iou(merged, xyxy[j]) >= merge_iou:\n",
    "                    # í•©ì§‘í•©(ë°”ìš´ë”© ë°•ìŠ¤)\n",
    "                    x1 = min(merged[0], xyxy[j][0])\n",
    "                    y1 = min(merged[1], xyxy[j][1])\n",
    "                    x2 = max(merged[2], xyxy[j][2])\n",
    "                    y2 = max(merged[3], xyxy[j][3])\n",
    "                    merged = (x1, y1, x2, y2)\n",
    "                    used[j] = True\n",
    "                    changed = True\n",
    "            new_xyxy.append(merged)\n",
    "        xyxy = new_xyxy\n",
    "\n",
    "    merged_boxes = [_xyxy_to_xywh(b) for b in xyxy]\n",
    "    merged_boxes.sort(key=lambda b: b[2]*b[3], reverse=True)\n",
    "    return merged_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ccb4c8-590d-4e34-853a-146157096447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "MODEL_DIR = './saved_models'\n",
    "CLASSIFIER_PATH = os.path.join(MODEL_DIR, 'classifier_K800_H576_S16_WGT.pkl')\n",
    "VOCAB_PATH      = os.path.join(MODEL_DIR, 'vocab_K800_H576_S16_WGT.pkl')\n",
    "\n",
    "classifier = joblib.load(CLASSIFIER_PATH)\n",
    "vocab = joblib.load(VOCAB_PATH)\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"Ants\",\"Bees\",\"Beetles\",\"Caterpillars\",\"Earthworms\",\"Earwigs\",\n",
    "    \"Grasshoppers\",\"Moths\",\"Slugs\",\"Snails\",\"Wasps\",\"Weevils\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb4c274a-04dc-4a82-ab27-161325a0d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dense_sift(img, step=16):\n",
    "    sift = cv2.SIFT_create()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kps = [cv2.KeyPoint(x, y, step)\n",
    "           for y in range(0, gray.shape[0], step)\n",
    "           for x in range(0, gray.shape[1], step)]\n",
    "    _, desc = sift.compute(gray, kps)\n",
    "    return desc\n",
    "\n",
    "def create_bovw_histogram(desc, vocab):\n",
    "    k = vocab.n_clusters\n",
    "    hist = np.zeros(k, np.float32)\n",
    "    if desc is not None:\n",
    "        words = vocab.predict(desc)\n",
    "        hist, _ = np.histogram(words, bins=np.arange(k+1))\n",
    "        hist = hist / (np.linalg.norm(hist) + 1e-6)\n",
    "    return hist\n",
    "\n",
    "def get_color_histogram(img, bins=16):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    chans = cv2.split(hsv)\n",
    "    hists = [cv2.calcHist([c],[0],None,[bins],[0,256]) for c in chans]\n",
    "    for h in hists: cv2.normalize(h, h)\n",
    "    return np.hstack([h.flatten() for h in hists])\n",
    "\n",
    "def extract_combined_features(img, vocab, W_BOVW=1.0, W_HOG=0.5, W_COLOR=1.0):\n",
    "    sift_desc = extract_dense_sift(img)\n",
    "    bovw = create_bovw_histogram(sift_desc, vocab)\n",
    "    h = cv2.HOGDescriptor((320,320), (128,128), (64,64), (64,64), 9)\n",
    "    hog_feat = h.compute(cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), (320,320))).flatten()\n",
    "    color_feat = get_color_histogram(img, bins=16)\n",
    "    return np.hstack([W_BOVW*bovw, W_HOG*hog_feat, W_COLOR*color_feat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f90a61-1fd7-449b-8e1a-42afdbefcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_classify(img):\n",
    "    mask = make_fg_mask_simple(img)\n",
    "    boxes = propose_boxes_from_mask(mask)\n",
    "    results = []\n",
    "\n",
    "    for (x, y, w, h) in boxes:\n",
    "        crop = img[y:y+h, x:x+w]\n",
    "        if crop.size == 0: continue\n",
    "        crop_resized = cv2.resize(crop, (320, 320))\n",
    "        feat = extract_combined_features(crop_resized, vocab)\n",
    "        pred = classifier.predict(feat.reshape(1, -1))[0]\n",
    "        results.append((CLASS_NAMES[pred], (x,y,w,h)))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d33f1855-9370-456a-a8e9-489257cba824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating full valid set (fixed): 100%|â–ˆ| 1095/1095 [01:05<00:00, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "ğŸ“Š Precision / Recall / F1 Breakdown (Full valid set, fixed)\n",
      "----------------------------------------------\n",
      "ğŸŸ  Detection Stage\n",
      " Precision : 55.50%\n",
      " Recall    : 48.92%\n",
      " F1-score  : 52.00%\n",
      "----------------------------------------------\n",
      "ğŸ”µ Classification Stage\n",
      " Precision : 52.59%\n",
      " Recall    : 25.73%\n",
      " F1-score  : 34.55%\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5549915397631133,\n",
       " 0.4891871737509321,\n",
       " 0.5200158541418946,\n",
       " 0.5259146341463414,\n",
       " 0.25727069351230425,\n",
       " 0.34551827741612423)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_full_valid_set_fixed(IMG_DIR, LBL_DIR, iou_thr=0.5):\n",
    "    img_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith('.jpg')]\n",
    "    total_gt = 0\n",
    "    det_TP, det_FP, det_FN = 0, 0, 0\n",
    "    cls_TP, cls_FP, cls_FN = 0, 0, 0\n",
    "\n",
    "    for fname in tqdm(img_files, desc=\"ğŸ” Evaluating full valid set (fixed)\"):\n",
    "        img_path = os.path.join(IMG_DIR, fname)\n",
    "        lbl_path = os.path.join(LBL_DIR, fname.replace('.jpg', '.txt'))\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        H, W = img.shape[:2]\n",
    "        gts = yolo_txt_to_xyxy(lbl_path, W, H)\n",
    "        total_gt += len(gts)\n",
    "        if len(gts) == 0:\n",
    "            continue\n",
    "\n",
    "        preds = detect_and_classify(img)\n",
    "        pred_boxes = [((x, y, x+w, y+h), cname) for cname, (x,y,w,h) in preds]\n",
    "\n",
    "        matched_gt = set()\n",
    "        matched_pred = set()\n",
    "\n",
    "        for i, (p_box, cname) in enumerate(pred_boxes):\n",
    "            best_iou, best_j = 0, -1\n",
    "            for j, (gt_cls, gt_box) in enumerate(gts):\n",
    "                if j in matched_gt: continue\n",
    "                iou = iou_xyxy(p_box, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou, best_j = iou, j\n",
    "            # íƒì§€ ì„±ê³µ\n",
    "            if best_iou >= iou_thr:\n",
    "                det_TP += 1\n",
    "                matched_gt.add(best_j)\n",
    "                matched_pred.add(i)\n",
    "                # ë¶„ë¥˜ê¹Œì§€ ë§ì€ ê²½ìš°\n",
    "                if cname == CLASS_NAMES[gts[best_j][0]]:\n",
    "                    cls_TP += 1\n",
    "                else:\n",
    "                    cls_FP += 1\n",
    "            else:\n",
    "                det_FP += 1\n",
    "\n",
    "        det_FN += (len(gts) - len(matched_gt))\n",
    "\n",
    "    # --- ê³„ì‚° (ì•ˆì •ì„± ì²´í¬) ---\n",
    "    det_precision = det_TP / max(1, (det_TP + det_FP))\n",
    "    det_recall = det_TP / max(1, (det_TP + det_FN))\n",
    "    det_f1 = 2 * det_precision * det_recall / max(1e-9, (det_precision + det_recall))\n",
    "\n",
    "    cls_precision = cls_TP / max(1, (cls_TP + cls_FP))\n",
    "    cls_recall = cls_TP / max(1, total_gt)   # ë¶„ëª¨ëŠ” ì „ì²´ GT (íƒì§€+ë¶„ë¥˜ ë‘˜ ë‹¤ ì„±ê³µí•´ì•¼ í•˜ë¯€ë¡œ)\n",
    "    cls_f1 = 2 * cls_precision * cls_recall / max(1e-9, (cls_precision + cls_recall))\n",
    "\n",
    "    print(\"\\n==============================================\")\n",
    "    print(\"ğŸ“Š Precision / Recall / F1 Breakdown (Full valid set, fixed)\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"ğŸŸ  Detection Stage\")\n",
    "    print(f\" Precision : {det_precision*100:.2f}%\")\n",
    "    print(f\" Recall    : {det_recall*100:.2f}%\")\n",
    "    print(f\" F1-score  : {det_f1*100:.2f}%\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"ğŸ”µ Classification Stage\")\n",
    "    print(f\" Precision : {cls_precision*100:.2f}%\")\n",
    "    print(f\" Recall    : {cls_recall*100:.2f}%\")\n",
    "    print(f\" F1-score  : {cls_f1*100:.2f}%\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    return (det_precision, det_recall, det_f1,\n",
    "            cls_precision, cls_recall, cls_f1)\n",
    "\n",
    "# ğŸš€ ì‹¤í–‰\n",
    "evaluate_full_valid_set_fixed(VAL_IMG_DIR, VAL_LBL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "076ec241-4327-48e5-825d-7a6e66386361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸš€ Evaluating End-to-End (Detection + Classification): 100%|â–ˆ| 1095/1095 [01:03<"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "ğŸ Final End-to-End Performance (Detection + Classification)\n",
      "----------------------------------------------\n",
      " Precision : 29.19%\n",
      " Recall    : 33.50%\n",
      " F1-score  : 31.19%\n",
      "----------------------------------------------\n",
      " GT objects: 1341\n",
      " True Positives : 345\n",
      " False Positives: 837\n",
      " False Negatives: 685\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2918781725888325, 0.33495145631067963, 0.3119349005424955)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_end_to_end(IMG_DIR, LBL_DIR, iou_thr=0.5):\n",
    "    img_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith('.jpg')]\n",
    "    total_gt, TP, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "    for fname in tqdm(img_files, desc=\"ğŸš€ Evaluating End-to-End (Detection + Classification)\"):\n",
    "        img_path = os.path.join(IMG_DIR, fname)\n",
    "        lbl_path = os.path.join(LBL_DIR, fname.replace('.jpg', '.txt'))\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        H, W = img.shape[:2]\n",
    "        gts = yolo_txt_to_xyxy(lbl_path, W, H)\n",
    "        total_gt += len(gts)\n",
    "        if len(gts) == 0:\n",
    "            continue\n",
    "\n",
    "        preds = detect_and_classify(img)\n",
    "        pred_boxes = [((x, y, x+w, y+h), cname) for cname, (x,y,w,h) in preds]\n",
    "\n",
    "        matched_gt = set()\n",
    "        matched_pred = set()\n",
    "\n",
    "        for i, (p_box, cname) in enumerate(pred_boxes):\n",
    "            best_iou, best_j = 0, -1\n",
    "            for j, (gt_cls, gt_box) in enumerate(gts):\n",
    "                if j in matched_gt:\n",
    "                    continue\n",
    "                iou = iou_xyxy(p_box, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou, best_j = iou, j\n",
    "\n",
    "            if best_iou >= iou_thr:\n",
    "                if cname == CLASS_NAMES[gts[best_j][0]]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1  # íƒì§€ëŠ” ë§ì•˜ì§€ë§Œ ë¶„ë¥˜ëŠ” í‹€ë¦¼\n",
    "                matched_gt.add(best_j)\n",
    "                matched_pred.add(i)\n",
    "            else:\n",
    "                FP += 1  # íƒì§€ ìì²´ê°€ ì˜ëª»ë¨\n",
    "\n",
    "        FN += (len(gts) - len(matched_gt))\n",
    "\n",
    "    # ìµœì¢… ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "    precision = TP / max(1, (TP + FP))\n",
    "    recall = TP / max(1, (TP + FN))\n",
    "    f1 = 2 * precision * recall / max(1e-9, precision + recall)\n",
    "\n",
    "    print(\"\\n==============================================\")\n",
    "    print(\"ğŸ Final End-to-End Performance (Detection + Classification)\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(f\" Precision : {precision*100:.2f}%\")\n",
    "    print(f\" Recall    : {recall*100:.2f}%\")\n",
    "    print(f\" F1-score  : {f1*100:.2f}%\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(f\" GT objects: {total_gt}\")\n",
    "    print(f\" True Positives : {TP}\")\n",
    "    print(f\" False Positives: {FP}\")\n",
    "    print(f\" False Negatives: {FN}\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "# ğŸš€ ì‹¤í–‰\n",
    "evaluate_end_to_end(VAL_IMG_DIR, VAL_LBL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a85c348-4b43-4bf5-adeb-68942dab27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_ap(rec, prec):\n",
    "    \"\"\"\n",
    "    Compute the average precision (AP) given recall and precision.\n",
    "    Method follows the VOC 2010/COCO convention.\n",
    "    \"\"\"\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # Precision smoothing\n",
    "    for i in range(len(mpre)-1, 0, -1):\n",
    "        mpre[i-1] = np.maximum(mpre[i-1], mpre[i])\n",
    "\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "    ap = np.sum((mrec[i+1] - mrec[i]) * mpre[i+1])\n",
    "    return ap\n",
    "\n",
    "\n",
    "def evaluate_map(IMG_DIR, LBL_DIR, iou_thr=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate mAP@0.5 for detection + classification pipeline\n",
    "    \"\"\"\n",
    "    img_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith('.jpg')]\n",
    "    all_detections = {cls: [] for cls in CLASS_NAMES}\n",
    "    all_annotations = {cls: 0 for cls in CLASS_NAMES}\n",
    "\n",
    "    # ---- 1. Collect detections & annotations ----\n",
    "    for fname in tqdm(img_files, desc=\"ğŸ“ˆ Collecting detections for mAP\"):\n",
    "        img_path = os.path.join(IMG_DIR, fname)\n",
    "        lbl_path = os.path.join(LBL_DIR, fname.replace('.jpg', '.txt'))\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        H, W = img.shape[:2]\n",
    "        gts = yolo_txt_to_xyxy(lbl_path, W, H)\n",
    "        preds = detect_and_classify(img)\n",
    "\n",
    "        detected_gt = []\n",
    "\n",
    "        for cname, (x, y, w, h) in preds:\n",
    "            pred_box = (x, y, x+w, y+h)\n",
    "            conf = 1.0  # or use detector probability if available\n",
    "            pred_cls = cname\n",
    "            all_detections[pred_cls].append({'conf': conf, 'bbox': pred_box, 'fname': fname})\n",
    "\n",
    "        for gt_cls, gt_box in gts:\n",
    "            all_annotations[CLASS_NAMES[gt_cls]] += 1\n",
    "\n",
    "    # ---- 2. Compute AP per class ----\n",
    "    aps = []\n",
    "    for cname in CLASS_NAMES:\n",
    "        detections = sorted(all_detections[cname], key=lambda x: x['conf'], reverse=True)\n",
    "        n_gt = all_annotations[cname]\n",
    "        if n_gt == 0:\n",
    "            continue\n",
    "\n",
    "        TP = np.zeros(len(detections))\n",
    "        FP = np.zeros(len(detections))\n",
    "        gt_used = {}\n",
    "\n",
    "        for i, det in enumerate(detections):\n",
    "            fname = det['fname']\n",
    "            lbl_path = os.path.join(LBL_DIR, fname.replace('.jpg', '.txt'))\n",
    "            img = cv2.imread(os.path.join(IMG_DIR, fname))\n",
    "            if img is None:\n",
    "                continue\n",
    "            H, W = img.shape[:2]\n",
    "            gts = yolo_txt_to_xyxy(lbl_path, W, H)\n",
    "            pred_box = det['bbox']\n",
    "\n",
    "            best_iou, best_j = 0, -1\n",
    "            for j, (gt_cls, gt_box) in enumerate(gts):\n",
    "                if CLASS_NAMES[gt_cls] != cname:\n",
    "                    continue\n",
    "                iou = iou_xyxy(pred_box, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou, best_j = iou, j\n",
    "\n",
    "            if best_iou >= iou_thr and (fname, best_j) not in gt_used:\n",
    "                TP[i] = 1\n",
    "                gt_used[(fname, best_j)] = True\n",
    "            else:\n",
    "                FP[i] = 1\n",
    "\n",
    "        TP_cum = np.cumsum(TP)\n",
    "        FP_cum = np.cumsum(FP)\n",
    "        rec = TP_cum / (n_gt + 1e-6)\n",
    "        prec = TP_cum / np.maximum(TP_cum + FP_cum, 1e-6)\n",
    "        ap = compute_ap(rec, prec)\n",
    "        aps.append(ap)\n",
    "        print(f\"AP({cname}) = {ap*100:.2f}%\")\n",
    "\n",
    "    mAP = np.mean(aps) if len(aps) > 0 else 0.0\n",
    "    print(\"\\n==============================================\")\n",
    "    print(f\"ğŸ mAP@0.5 (Detection+Classification) : {mAP*100:.2f}%\")\n",
    "    print(\"==============================================\")\n",
    "    return mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "307da83e-cfd5-479d-96a9-85ed89a22d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Collecting detections for mAP: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1095/1095 [01:01<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP(Ants) = 4.04%\n",
      "AP(Bees) = 11.92%\n",
      "AP(Beetles) = 4.73%\n",
      "AP(Caterpillars) = 1.36%\n",
      "AP(Earthworms) = 3.45%\n",
      "AP(Earwigs) = 3.25%\n",
      "AP(Grasshoppers) = 6.97%\n",
      "AP(Moths) = 44.04%\n",
      "AP(Slugs) = 3.00%\n",
      "AP(Snails) = 17.27%\n",
      "AP(Wasps) = 23.47%\n",
      "AP(Weevils) = 28.69%\n",
      "\n",
      "==============================================\n",
      "ğŸ mAP@0.5 (Detection+Classification) : 12.68%\n",
      "==============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.1268271182872758)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_map(VAL_IMG_DIR, VAL_LBL_DIR, iou_thr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd24be9-38d3-4e26-a67c-871e47f44fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f34586-80a8-4a89-9c10-79abbe4f3081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b882b092",
   "metadata": {},
   "source": [
    "# XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459b99ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Balanced] Build binary crops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:59<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[í´ë˜ìŠ¤ë³„ ì–‘ì„± í™•ë³´ í˜„í™©]\n",
      "  class  0 :   223 /   500    \n",
      "  class  1 :   119 /   500 (!)\n",
      "  class  2 :   112 /   500 (!)\n",
      "  class  3 :   183 /   500 (!)\n",
      "  class  4 :   105 /   500 (!)\n",
      "  class  5 :   109 /   500 (!)\n",
      "  class  6 :   120 /   500 (!)\n",
      "  class  7 :   170 /   500 (!)\n",
      "  class  8 :    86 /   500 (!)\n",
      "  class  9 :   146 /   500 (!)\n",
      "  class 10 :   118 /   500 (!)\n",
      "  class 11 :    94 /   500 (!)\n",
      "  -> ì¼ë¶€ í´ë˜ìŠ¤ëŠ” ìµœì†Œ ëª©í‘œ ë¯¸ë‹¬(ë°ì´í„° ë¶„í¬ í•œê³„ ê°€ëŠ¥).\n",
      "[INFO] ì–‘ì„±(ì „ê²½) 1,585 / ìŒì„±(ë°°ê²½) 2,771 / ì´ 4,356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Balanced] Build binary crops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:29<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[í´ë˜ìŠ¤ë³„ ì–‘ì„± í™•ë³´ í˜„í™©]\n",
      "  class  0 :   100 /   250    \n",
      "  class  1 :    60 /   250    \n",
      "  class  2 :    54 /   250    \n",
      "  class  3 :    61 /   250    \n",
      "  class  4 :    40 /   250    \n",
      "  class  5 :    66 /   250    \n",
      "  class  6 :    54 /   250    \n",
      "  class  7 :    79 /   250    \n",
      "  class  8 :    55 /   250    \n",
      "  class  9 :    77 /   250    \n",
      "  class 10 :    80 /   250    \n",
      "  class 11 :    72 /   250    \n",
      "[INFO] ì–‘ì„±(ì „ê²½) 798 / ìŒì„±(ë°°ê²½) 1,473 / ì´ 2,271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract feats: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4356/4356 [00:23<00:00, 186.87it/s]\n",
      "Extract feats: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2271/2271 [00:12<00:00, 179.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVM] í•™ìŠµ ì™„ë£Œ: 88.34s, classes=[0 1]\n",
      "[Calib] ë³´ì • ì™„ë£Œ: 342.35s\n",
      "[25/500] ëˆ„ì  GT:29 Pred:23  TP:11 FP:12 FN:18\n",
      "[50/500] ëˆ„ì  GT:56 Pred:46  TP:21 FP:25 FN:35\n",
      "[75/500] ëˆ„ì  GT:88 Pred:73  TP:33 FP:40 FN:55\n",
      "[100/500] ëˆ„ì  GT:125 Pred:97  TP:50 FP:47 FN:75\n",
      "[125/500] ëˆ„ì  GT:173 Pred:121  TP:63 FP:58 FN:110\n",
      "[150/500] ëˆ„ì  GT:203 Pred:151  TP:81 FP:70 FN:122\n",
      "[175/500] ëˆ„ì  GT:232 Pred:178  TP:98 FP:80 FN:134\n",
      "[200/500] ëˆ„ì  GT:267 Pred:204  TP:115 FP:89 FN:152\n",
      "[225/500] ëˆ„ì  GT:293 Pred:227  TP:130 FP:97 FN:163\n",
      "[250/500] ëˆ„ì  GT:327 Pred:256  TP:148 FP:108 FN:179\n",
      "[275/500] ëˆ„ì  GT:363 Pred:278  TP:165 FP:113 FN:198\n",
      "[300/500] ëˆ„ì  GT:394 Pred:303  TP:182 FP:121 FN:212\n",
      "[325/500] ëˆ„ì  GT:427 Pred:331  TP:192 FP:139 FN:235\n",
      "[350/500] ëˆ„ì  GT:462 Pred:361  TP:205 FP:156 FN:257\n",
      "[375/500] ëˆ„ì  GT:491 Pred:386  TP:221 FP:165 FN:270\n",
      "[400/500] ëˆ„ì  GT:517 Pred:412  TP:236 FP:176 FN:281\n",
      "[425/500] ëˆ„ì  GT:543 Pred:441  TP:252 FP:189 FN:291\n",
      "[450/500] ëˆ„ì  GT:568 Pred:464  TP:267 FP:197 FN:301\n",
      "[475/500] ëˆ„ì  GT:594 Pred:490  TP:285 FP:205 FN:309\n",
      "[500/500] ëˆ„ì  GT:622 Pred:515  TP:299 FP:216 FN:323\n",
      "\n",
      "========== [Binary Eval @ IoU=0.50] ==========\n",
      "Ground Truth Objects : 622\n",
      "Total Predictions    : 515\n",
      "True Positives (TP)  : 299\n",
      "False Positives (FP) : 216\n",
      "False Negatives (FN) : 323\n",
      "---------------------------------------------\n",
      "Precision : 0.5806\n",
      "Recall    : 0.4807\n",
      "F1-Score  : 0.5259\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# test2 í›„ì† ì…€ (ì™„ì „ ì‹ ê·œ): \n",
    "#   ì „ê²½ ë§ˆìŠ¤í¬ + ì—°ê²°ìš”ì†Œ í›„ë³´ â†’ HOG(+ìƒ‰) + SVM(ì´ì§„: ê³¤ì¶©/ë°°ê²½) â†’ \n",
    "#   í´ë˜ìŠ¤-ë¬´ì‹œ í‰ê°€(Precision/Recall/F1) + í´ë˜ìŠ¤ë³„ ê· í˜• ì–‘ì„± ìƒ˜í”Œë§\n",
    "# ------------------------------------------------------------\n",
    "# â€» ì „ì œ: test2ì—ì„œ ì•„ë˜ í•¨ìˆ˜ê°€ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "#    - FG ë§ˆìŠ¤í¬: make_fg_mask_texture(bgr) ë˜ëŠ” make_fg_mask_simple(bgr)\n",
    "#    - í›„ë³´ë°•ìŠ¤: propose_boxes_from_mask(mask)   # (x,y,w,h) ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "# â€» ê²½ë¡œ/ì„í¬íŠ¸: test2ì˜ ê²½ë¡œ ì„¤ì •(../data/...)ê³¼ importê°€ ì´ë¯¸ ì‹¤í–‰ëœ ìƒíƒœ\n",
    "# ============================================================\n",
    "\n",
    "import os, random, time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# -----------------------------\n",
    "# [A] íŒŒì´í”„ë¼ì¸ ì „ì—­ íŒŒë¼ë¯¸í„°\n",
    "# -----------------------------\n",
    "# ë°ì´í„° ìƒ˜í”Œë§(ë„ˆë¬´ í¬ë©´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ìƒí•œ)\n",
    "MAX_TRAIN_IMAGES = 1000\n",
    "MAX_VAL_IMAGES   = 500\n",
    "RANDOM_SEED      = 42\n",
    "random.seed(RANDOM_SEED); np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# HOG ìœˆë„/íŒŒë¼ë¯¸í„° (ê³ ì • í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í›„ íŠ¹ì§• ì¶”ì¶œ)\n",
    "WIN_H, WIN_W     = 128, 128        # HOG ì…ë ¥ í¬ê¸° (H,W)\n",
    "ORIENTATIONS     = 12               # ë°©í–¥ ìˆ˜\n",
    "PIXELS_PER_CELL  = (8, 8)         # ì…€ í¬ê¸°(px)\n",
    "CELLS_PER_BLOCK  = (2, 2)          # ë¸”ë¡(ì…€) ìˆ˜\n",
    "\n",
    "# ìƒ‰ íˆìŠ¤í† ê·¸ë¨(HSV) ì‚¬ìš© (ë°°ê²½ê³¼ì˜ ìƒ‰ ì°¨ ë¶„ë¦¬ì— ë„ì›€)\n",
    "USE_HSV_HIST     = True\n",
    "H_BINS, S_BINS, V_BINS = 32, 16, 16\n",
    "\n",
    "# ì´ì§„ ë¼ë²¨ ê¸°ì¤€ (GTì™€ì˜ IoUë¡œ ì–‘/ìŒì„± ì •ì˜)\n",
    "IOU_POS_THR = 0.7   # í›„ë³´ê°€ GTì™€ ì´ ì´ìƒ ê²¹ì¹˜ë©´ ì–‘ì„±(ì „ê²½)\n",
    "IOU_NEG_THR = 0.10   # ëœë¤ ì°½ì´ ëª¨ë“  GTì™€ ì´ ì´í•˜ì´ë©´ ìŒì„±(ë°°ê²½)\n",
    "\n",
    "# ì´ë¯¸ì§€ë‹¹ í¬ë¡­ ìˆ˜/ë¹„ìœ¨ ì œí•œ(ë°ì´í„° í­ì£¼ ë°©ì§€)\n",
    "MAX_CROPS_PER_IMG = 12\n",
    "NEG_POS_RATIO     = 2.0\n",
    "MAX_NEG_TOTAL     = 30000\n",
    "\n",
    "# í´ë˜ìŠ¤ ê· í˜•(ì–‘ì„± ìƒ˜í”Œë§ ë‹¨ê³„ì—ì„œë§Œ class_id ì‚¬ìš©)\n",
    "MAX_POS_PER_CLASS = 500  # ê° í´ë˜ìŠ¤ë³„ ì–‘ì„± í¬ë¡­ ìµœëŒ€ í™•ë³´ ìˆ˜\n",
    "MIN_POS_PER_CLASS = 200   # (ë¦¬í¬íŠ¸ìš©) ì´ìƒì  ìµœì†Œ ëª©í‘œ\n",
    "\n",
    "# ë¶„ë¥˜/ê²€ì¶œ/í‰ê°€\n",
    "SVM_C              = 1.5\n",
    "SVM_MAX_ITER       = 5000\n",
    "DET_THRESH         = 0.12    # p(foreground) ì»·ì˜¤í”„\n",
    "NMS_IOU_THRESHOLD  = 0.6    # NMS IoU(í´ë˜ìŠ¤ ë¬´ì‹œ)\n",
    "MAX_PROPOSALS_PER_IMAGE = 200\n",
    "EVAL_IOU_THR       = 0.50    # í‰ê°€ ë§¤ì¹­ IoU\n",
    "\n",
    "# ì „ê²½ ë§ˆìŠ¤í¬ í•¨ìˆ˜ ì„ íƒ: test2ì—ì„œ ì •ì˜ëœ í•¨ìˆ˜ëª…ì„ ì—°ê²°\n",
    "# FG_MASK_FN = make_fg_mask_texture\n",
    "FG_MASK_FN = make_fg_mask_simple   # í•„ìš” ì‹œ ìœ„/ì•„ë˜ ì¤‘ íƒ1\n",
    "\n",
    "# -----------------------------\n",
    "# [B] IOU/NMS/ë¼ë²¨ íŒŒì„œ ìœ í‹¸\n",
    "# -----------------------------\n",
    "def xywh_to_xyxy(b):\n",
    "    x,y,w,h = b\n",
    "    return (x, y, x+w, y+h)\n",
    "\n",
    "def clip_box_xywh(b, W, H):\n",
    "    x,y,w,h = map(int, b)\n",
    "    x = max(0, min(x, W-1)); y = max(0, min(y, H-1))\n",
    "    w = max(1, min(w, W-x)); h = max(1, min(h, H-y))\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    ax1,ay1,ax2,ay2 = a\n",
    "    bx1,by1,bx2,by2 = b\n",
    "    iw = max(0, min(ax2,bx2) - max(ax1,bx1) + 1)\n",
    "    ih = max(0, min(ay2,by2) - max(ay1,by1) + 1)\n",
    "    inter = iw * ih\n",
    "    if inter <= 0: return 0.0\n",
    "    area_a = (ax2-ax1+1)*(ay2-ay1+1); area_b = (bx2-bx1+1)*(by2-by1+1)\n",
    "    return inter / max(1.0, (area_a + area_b - inter))\n",
    "\n",
    "def nms_xyxy(boxes, scores, iou_thr=0.5):\n",
    "    if len(boxes)==0: return [], []\n",
    "    boxes = np.asarray(boxes, dtype=np.float32)\n",
    "    scores= np.asarray(scores, dtype=np.float32)\n",
    "    x1,y1,x2,y2 = boxes.T\n",
    "    areas = (x2-x1+1)*(y2-y1+1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep=[]\n",
    "    while order.size>0:\n",
    "        i=order[0]; keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        w = np.maximum(0.0, xx2-xx1+1); h = np.maximum(0.0, yy2-yy1+1)\n",
    "        inter = w*h\n",
    "        iou = inter/(areas[i] + areas[order[1:]] - inter + 1e-9)\n",
    "        order = order[1:][iou <= iou_thr]\n",
    "    return boxes[keep].astype(int).tolist(), scores[keep].tolist()\n",
    "\n",
    "def fallback_load_annotations(lbl_path, img_hw):\n",
    "    \"\"\"\n",
    "    YOLO txt í¬ë§· -> [(cid, (x,y,w,h)), ...] (í”½ì…€ ì¢Œí‘œ)\n",
    "    * ì—¬ê¸°ì„œëŠ” 'cid'ëŠ” í•™ìŠµ ë¼ë²¨ë¡œ ì“°ì§€ ì•Šì§€ë§Œ, 'ì–‘ì„± ìƒ˜í”Œ ê· í˜•'ì—ë§Œ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    H, W = img_hw\n",
    "    out=[]\n",
    "    if not os.path.exists(lbl_path):\n",
    "        return out\n",
    "    with open(lbl_path, 'r') as f:\n",
    "        for line in f:\n",
    "            s=line.strip().split()\n",
    "            if len(s)!=5: continue\n",
    "            cid, xc, yc, ww, hh = int(s[0]), float(s[1]), float(s[2]), float(s[3]), float(s[4])\n",
    "            x = int((xc-ww/2)*W); y = int((yc-hh/2)*H)\n",
    "            w = int(ww*W); h = int(hh*H)\n",
    "            out.append((cid, (x,y,w,h)))\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# [C] íŠ¹ì§• ì¶”ì¶œ (HOG + HSV íˆìŠ¤í† )\n",
    "# -----------------------------\n",
    "def _resize_crop(bgr, box_xywh, out_hw):\n",
    "    H,W = bgr.shape[:2]\n",
    "    x,y,w,h = clip_box_xywh(box_xywh, W, H)\n",
    "    crop = bgr[y:y+h, x:x+w]\n",
    "    if crop.size==0: return None\n",
    "    return cv2.resize(crop, (out_hw[1], out_hw[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def _hsv_hist(bgr, h_bins=32, s_bins=16, v_bins=16):\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    histH = cv2.calcHist([hsv],[0],None,[h_bins],[0,180]).flatten()\n",
    "    histS = cv2.calcHist([hsv],[1],None,[s_bins],[0,256]).flatten()\n",
    "    histV = cv2.calcHist([hsv],[2],None,[v_bins],[0,256]).flatten()\n",
    "    hist  = np.concatenate([histH, histS, histV]).astype(np.float32)\n",
    "    return (hist / (np.sum(hist)+1e-6))\n",
    "\n",
    "def extract_features(bgr_crop):\n",
    "    \"\"\"\n",
    "    - ê·¸ë ˆì´ìŠ¤ì¼€ì¼ HOG (ëª¨ì–‘/ìœ¤ê³½)\n",
    "    - (ì˜µì…˜) HSV íˆìŠ¤í† ê·¸ë¨ (ìƒ‰ìƒ ë¶„ë¦¬)\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(bgr_crop, cv2.COLOR_BGR2GRAY)\n",
    "    fd = hog(gray, orientations=ORIENTATIONS, pixels_per_cell=PIXELS_PER_CELL,\n",
    "             cells_per_block=CELLS_PER_BLOCK, block_norm='L2-Hys',\n",
    "             visualize=False, transform_sqrt=True, feature_vector=True).astype(np.float32)\n",
    "    if USE_HSV_HIST:\n",
    "        hist = _hsv_hist(bgr_crop, H_BINS, S_BINS, V_BINS)\n",
    "        fd = np.concatenate([fd, hist]).astype(np.float32)\n",
    "    return fd\n",
    "\n",
    "# -----------------------------\n",
    "# [D] ê²½ë¡œ ìœ í‹¸/ìƒ˜í”Œë§\n",
    "# -----------------------------\n",
    "def _sample_image_paths(img_dir, max_n, seed=42):\n",
    "    paths = [os.path.join(img_dir, f) for f in os.listdir(img_dir)\n",
    "             if f.lower().endswith(('.jpg','.jpeg','.png','.bmp'))]\n",
    "    random.Random(seed).shuffle(paths)\n",
    "    return paths[:max_n]\n",
    "\n",
    "# -----------------------------\n",
    "# [E] (í•µì‹¬) ì´ì§„ í•™ìŠµ í¬ë¡­ ìƒì„± - \"í´ë˜ìŠ¤ ê· í˜• ì–‘ì„±\"\n",
    "# -----------------------------\n",
    "def build_binary_crops_from_dir_balanced(\n",
    "    IMG_DIR, LBL_DIR,\n",
    "    max_images=MAX_TRAIN_IMAGES,\n",
    "    iou_pos_thr=IOU_POS_THR, iou_neg_thr=IOU_NEG_THR,\n",
    "    max_crops_per_img=MAX_CROPS_PER_IMG,\n",
    "    neg_pos_ratio=NEG_POS_RATIO,\n",
    "    max_neg_total=MAX_NEG_TOTAL,\n",
    "    max_pos_per_class=MAX_POS_PER_CLASS,\n",
    "    min_pos_per_class=MIN_POS_PER_CLASS,\n",
    "    seed=RANDOM_SEED\n",
    "):\n",
    "    \"\"\"\n",
    "    ìµœì¢… ë¼ë²¨ì€ ì´ì§„(0=ë°°ê²½, 1=ì „ê²½/ê³¤ì¶©).\n",
    "    ë‹¨, 'ì–‘ì„± ìƒ˜í”Œ'ì„ ë½‘ì„ ë•Œë§Œ class_idë¥¼ ì‚¬ìš©í•´ í´ë˜ìŠ¤ë³„ë¡œ ê³ ë¥´ê²Œ(ìƒí•œ/ìµœì†Œ ëª©í‘œ) í™•ë³´.\n",
    "    - ì–‘ì„±: (a) GT ë°•ìŠ¤ (b) ì „ê²½ í›„ë³´ ì¤‘ GTì™€ IoU>=iou_pos_thr\n",
    "    - ìŒì„±: ëœë¤ ì°½ ì¤‘ ëª¨ë“  GTì™€ IoU<=iou_neg_thr\n",
    "    \"\"\"\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    img_paths = _sample_image_paths(IMG_DIR, max_images, seed=seed)\n",
    "    if len(img_paths)==0: \n",
    "        raise FileNotFoundError(f\"No images in {IMG_DIR}\")\n",
    "\n",
    "    # í´ë˜ìŠ¤ ì§‘í•© ìŠ¤ìº”\n",
    "    per_class_count = {}\n",
    "    per_class_quota = {}\n",
    "    class_seen = set()\n",
    "    for p in img_paths:\n",
    "        bgr = cv2.imread(p); \n",
    "        if bgr is None: continue\n",
    "        H,W = bgr.shape[:2]\n",
    "        lbl = os.path.join(LBL_DIR, os.path.splitext(os.path.basename(p))[0]+'.txt')\n",
    "        gts = fallback_load_annotations(lbl, (H,W))\n",
    "        for cid,_ in gts: class_seen.add(cid)\n",
    "    for cid in sorted(class_seen):\n",
    "        per_class_count[cid] = 0\n",
    "        per_class_quota[cid] = max_pos_per_class\n",
    "\n",
    "    pos_crops, pos_labels = [], []\n",
    "    neg_crops, neg_labels = [], []\n",
    "    total_neg = 0\n",
    "\n",
    "    for p in tqdm(img_paths, desc=\"[Balanced] Build binary crops\"):\n",
    "        bgr = cv2.imread(p); \n",
    "        if bgr is None: continue\n",
    "        H,W = bgr.shape[:2]\n",
    "        img_id = os.path.splitext(os.path.basename(p))[0]\n",
    "        lbl   = os.path.join(LBL_DIR, img_id + '.txt')\n",
    "        gts   = fallback_load_annotations(lbl, (H,W))  # [(cid,(x,y,w,h)),...]\n",
    "\n",
    "        # ì „ê²½ í›„ë³´(ë³´ê°•ìš©)\n",
    "        mask  = FG_MASK_FN(bgr)\n",
    "        props = propose_boxes_from_mask(mask) or []\n",
    "\n",
    "        added_pos = 0\n",
    "\n",
    "        # (a) GT ìì²´ë¥¼ í´ë˜ìŠ¤ ê· í˜•ìœ¼ë¡œ ì–‘ì„± í™•ë³´\n",
    "        for cid, (x,y,w,h) in gts:\n",
    "            if per_class_count.get(cid,0) >= per_class_quota.get(cid,0): \n",
    "                continue\n",
    "            crop = _resize_crop(bgr, (x,y,w,h), (WIN_H, WIN_W))\n",
    "            if crop is None: continue\n",
    "            pos_crops.append(crop); pos_labels.append(1)\n",
    "            per_class_count[cid] += 1; added_pos += 1\n",
    "            if added_pos >= max_crops_per_img: break\n",
    "\n",
    "        # (b) í›„ë³´ ì¤‘ GTì™€ ì˜ ê²¹ì¹˜ëŠ” ê²ƒ(ê°™ì€ í´ë˜ìŠ¤ quota ë‚¨ì•„ìˆì„ ë•Œë§Œ) ë³´ê°•\n",
    "        if added_pos < max_crops_per_img and len(props)>0 and len(gts)>0:\n",
    "            gt_xyxy = [(cid, xywh_to_xyxy(bb)) for cid,bb in gts]\n",
    "            for (px,py,pw,ph) in props:\n",
    "                if added_pos >= max_crops_per_img: break\n",
    "                p_xyxy = xywh_to_xyxy((px,py,pw,ph))\n",
    "                # quota ë‚¨ì€ í´ë˜ìŠ¤ ì¤‘ ê°€ì¥ IoU í° GT ì°¾ê¸°\n",
    "                best_iou, best_cid = 0.0, None\n",
    "                for cid, g in gt_xyxy:\n",
    "                    if per_class_count[cid] >= per_class_quota[cid]:\n",
    "                        continue\n",
    "                    iou = iou_xyxy(p_xyxy, g)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou, best_cid = iou, cid\n",
    "                if best_cid is not None and best_iou >= iou_pos_thr:\n",
    "                    crop = _resize_crop(bgr, (px,py,pw,ph), (WIN_H, WIN_W))\n",
    "                    if crop is None: continue\n",
    "                    pos_crops.append(crop); pos_labels.append(1)\n",
    "                    per_class_count[best_cid] += 1; added_pos += 1\n",
    "\n",
    "        # (c) ìŒì„±: ì´ë¯¸ì§€ë‹¹ ìŒì„±/ì–‘ì„± ë¹„ìœ¨ ì œí•œ\n",
    "        want_neg = min(int(neg_pos_ratio*added_pos), max_crops_per_img - added_pos)\n",
    "        trials = 0\n",
    "        gt_boxes_xyxy = [xywh_to_xyxy(bb) for _,bb in gts]\n",
    "        while want_neg > 0 and total_neg < max_neg_total and trials < 60:\n",
    "            trials += 1\n",
    "            rw = np.random.randint(int(0.6*WIN_W), int(1.4*WIN_W))\n",
    "            rh = np.random.randint(int(0.6*WIN_H), int(1.4*WIN_H))\n",
    "            rx = np.random.randint(0, max(1, W - rw))\n",
    "            ry = np.random.randint(0, max(1, H - rh))\n",
    "            r_xyxy = (rx, ry, rx+rw, ry+rh)\n",
    "            ok=True\n",
    "            for g in gt_boxes_xyxy:\n",
    "                if iou_xyxy(r_xyxy, g) > iou_neg_thr:\n",
    "                    ok=False; break\n",
    "            if not ok: continue\n",
    "            crop = _resize_crop(bgr, (rx,ry,rw,rh), (WIN_H, WIN_W))\n",
    "            if crop is None: continue\n",
    "            neg_crops.append(crop); neg_labels.append(0)\n",
    "            total_neg += 1; want_neg -= 1\n",
    "\n",
    "    # (ë¦¬í¬íŠ¸) í´ë˜ìŠ¤ë³„ ì–‘ì„± í™•ë³´ í˜„í™©\n",
    "    lacking = {cid: cnt for cid,cnt in per_class_count.items() if cnt < min_pos_per_class}\n",
    "    print(\"\\n[í´ë˜ìŠ¤ë³„ ì–‘ì„± í™•ë³´ í˜„í™©]\")\n",
    "    for cid in sorted(per_class_count.keys()):\n",
    "        mark = \"(!)\" if cid in lacking else \"   \"\n",
    "        print(f\"  class {cid:2d} : {per_class_count[cid]:5d} / {max_pos_per_class:5d} {mark}\")\n",
    "    if len(lacking)>0:\n",
    "        print(\"  -> ì¼ë¶€ í´ë˜ìŠ¤ëŠ” ìµœì†Œ ëª©í‘œ ë¯¸ë‹¬(ë°ì´í„° ë¶„í¬ í•œê³„ ê°€ëŠ¥).\")\n",
    "\n",
    "    crops  = pos_crops + neg_crops\n",
    "    labels = pos_labels + neg_labels\n",
    "    print(f\"[INFO] ì–‘ì„±(ì „ê²½) {len(pos_labels):,} / ìŒì„±(ë°°ê²½) {len(neg_labels):,} / ì´ {len(labels):,}\")\n",
    "    return crops, labels, per_class_count\n",
    "\n",
    "# -----------------------------\n",
    "# [F] íŠ¹ì§•í–‰ë ¬ ìƒì„± & í•™ìŠµ\n",
    "# -----------------------------\n",
    "def feats_from_crops(crops):\n",
    "    X=[]\n",
    "    for c in tqdm(crops, desc=\"Extract feats\"):\n",
    "        X.append(extract_features(c))\n",
    "    return np.asarray(X, dtype=np.float32)\n",
    "\n",
    "# Train/Val ì´ì§„ í¬ë¡­ ìƒì„± (í´ë˜ìŠ¤ ê· í˜•)\n",
    "train_crops, train_labels, pos_per_class = build_binary_crops_from_dir_balanced(\n",
    "    TRAIN_IMG_DIR, TRAIN_LBL_DIR,\n",
    "    max_images=MAX_TRAIN_IMAGES,\n",
    "    iou_pos_thr=IOU_POS_THR, iou_neg_thr=IOU_NEG_THR,\n",
    "    max_crops_per_img=MAX_CROPS_PER_IMG,\n",
    "    neg_pos_ratio=NEG_POS_RATIO,\n",
    "    max_neg_total=MAX_NEG_TOTAL,\n",
    "    max_pos_per_class=MAX_POS_PER_CLASS,\n",
    "    min_pos_per_class=MIN_POS_PER_CLASS\n",
    ")\n",
    "\n",
    "val_crops, val_labels, _ = build_binary_crops_from_dir_balanced(\n",
    "    VAL_IMG_DIR, VAL_LBL_DIR,\n",
    "    max_images=MAX_VAL_IMAGES,\n",
    "    iou_pos_thr=IOU_POS_THR, iou_neg_thr=IOU_NEG_THR,\n",
    "    max_crops_per_img=MAX_CROPS_PER_IMG,\n",
    "    neg_pos_ratio=NEG_POS_RATIO,\n",
    "    max_neg_total=MAX_NEG_TOTAL,\n",
    "    max_pos_per_class=MAX_POS_PER_CLASS//2,  # ê²€ì¦ì€ ë‹¤ì†Œ ì‘ê²Œ\n",
    "    min_pos_per_class=0\n",
    ")\n",
    "\n",
    "# íŠ¹ì§•í™”\n",
    "X_train = feats_from_crops(train_crops)\n",
    "y_train = np.asarray(train_labels, dtype=np.int64)\n",
    "X_val   = feats_from_crops(val_crops)\n",
    "y_val   = np.asarray(val_labels, dtype=np.int64)\n",
    "\n",
    "# í‘œì¤€í™” + SVM ì´ì§„ í•™ìŠµ + í™•ë¥ ë³´ì •\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "\n",
    "svm_base = LinearSVC(C=SVM_C, max_iter=SVM_MAX_ITER, class_weight='balanced', dual=True)\n",
    "t0=time.time(); svm_base.fit(X_train_sc, y_train); t1=time.time()\n",
    "print(f\"[SVM] í•™ìŠµ ì™„ë£Œ: {t1-t0:.2f}s, classes={svm_base.classes_}\")\n",
    "\n",
    "clf = CalibratedClassifierCV(svm_base, cv=3, method='sigmoid')\n",
    "t0=time.time(); clf.fit(X_train_sc, y_train); t1=time.time()\n",
    "print(f\"[Calib] ë³´ì • ì™„ë£Œ: {t1-t0:.2f}s\")\n",
    "\n",
    "# -----------------------------\n",
    "# [G] ì´ì§„ ë””í…í„°(ì „ê²½ í›„ë³´ë§Œ â†’ ê³¤ì¶©/ë°°ê²½ íŒì •)\n",
    "# -----------------------------\n",
    "def detect_binary(bgr, det_thr=DET_THRESH, nms_iou=NMS_IOU_THRESHOLD, max_props=MAX_PROPOSALS_PER_IMAGE):\n",
    "    \"\"\"\n",
    "    ë°˜í™˜: list[(score, (x1,y1,x2,y2)), ...]  # score= p(foreground)\n",
    "    \"\"\"\n",
    "    mask  = FG_MASK_FN(bgr)\n",
    "    props = propose_boxes_from_mask(mask) or []\n",
    "    preds=[]\n",
    "    for (x,y,w,h) in props[:max_props]:\n",
    "        crop = _resize_crop(bgr, (x,y,w,h), (WIN_H, WIN_W))\n",
    "        if crop is None: continue\n",
    "        f   = extract_features(crop).reshape(1,-1)\n",
    "        fsc = scaler.transform(f)\n",
    "        prob = clf.predict_proba(fsc)[0]  # [p(bg), p(fg)]\n",
    "        p_fg = float(prob[1])\n",
    "        if p_fg >= det_thr:\n",
    "            preds.append((p_fg, xywh_to_xyxy((x,y,w,h))))\n",
    "    if len(preds)==0: return []\n",
    "    boxes  = [bb for _,bb in preds]\n",
    "    scores = [sc for sc,_ in preds]\n",
    "    b_n, s_n = nms_xyxy(boxes, scores, iou_thr=nms_iou)\n",
    "    return list(zip(s_n, b_n))\n",
    "\n",
    "# [H] í´ë˜ìŠ¤-ë¬´ì‹œ ì„±ëŠ¥ í‰ê°€(Precision/Recall/F1)\n",
    "# -----------------------------\n",
    "def evaluate_binary_detector_on_dir(IMG_DIR, LBL_DIR, max_imgs=MAX_VAL_IMAGES, iou_thr=EVAL_IOU_THR, verbose_every=25):\n",
    "    paths = _sample_image_paths(IMG_DIR, max_imgs, seed=RANDOM_SEED+7)\n",
    "    TP=0; FP=0; FN=0; total_gt=0; total_pred=0\n",
    "\n",
    "    for i,p in enumerate(paths,1):\n",
    "        bgr = cv2.imread(p)\n",
    "        if bgr is None: continue\n",
    "        H,W = bgr.shape[:2]\n",
    "        lbl = os.path.join(LBL_DIR, os.path.splitext(os.path.basename(p))[0]+'.txt')\n",
    "        gts = fallback_load_annotations(lbl, (H,W))\n",
    "        gt_boxes = [xywh_to_xyxy(bb) for _,bb in gts]\n",
    "        total_gt += len(gt_boxes)\n",
    "\n",
    "        preds = detect_binary(bgr, det_thr=DET_THRESH, nms_iou=NMS_IOU_THRESHOLD)\n",
    "        pred_boxes = [bb for _,bb in preds]\n",
    "        total_pred += len(pred_boxes)\n",
    "\n",
    "        used=set()\n",
    "        for score, bb in preds:   # ê³ ë“ì  ë¨¼ì € ë“¤ì–´ì˜´\n",
    "            best_iou, best_j = 0.0, -1\n",
    "            for j,g in enumerate(gt_boxes):\n",
    "                if j in used: continue\n",
    "                iou = iou_xyxy(bb, g)\n",
    "                if iou > best_iou:\n",
    "                    best_iou, best_j = iou, j\n",
    "            if best_iou >= iou_thr:\n",
    "                TP += 1; used.add(best_j)\n",
    "            else:\n",
    "                FP += 1\n",
    "        FN += (len(gt_boxes) - len(used))\n",
    "\n",
    "        if verbose_every and (i%verbose_every==0):\n",
    "            print(f\"[{i}/{len(paths)}] ëˆ„ì  GT:{total_gt} Pred:{total_pred}  TP:{TP} FP:{FP} FN:{FN}\")\n",
    "\n",
    "    prec = TP / max(1, TP+FP)\n",
    "    rec  = TP / max(1, TP+FN)\n",
    "    f1   = 2*prec*rec / max(1e-9, (prec+rec))\n",
    "    print(\"\\n========== [Binary Eval @ IoU=%.2f] ==========\"%iou_thr)\n",
    "    print(f\"Ground Truth Objects : {total_gt}\")\n",
    "    print(f\"Total Predictions    : {total_pred}\")\n",
    "    print(f\"True Positives (TP)  : {TP}\")\n",
    "    print(f\"False Positives (FP) : {FP}\")\n",
    "    print(f\"False Negatives (FN) : {FN}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Precision : {prec:.4f}\")\n",
    "    print(f\"Recall    : {rec:.4f}\")\n",
    "    print(f\"F1-Score  : {f1:.4f}\")\n",
    "    print(\"=============================================\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# [I] í‰ê°€ ì‹¤í–‰ (valid ë¨¼ì €, ì—†ìœ¼ë©´ trainë¡œ ê°ˆì•„íƒ€ë„ ë¨)\n",
    "# -----------------------------\n",
    "if os.path.isdir(VAL_IMG_DIR) and len(os.listdir(VAL_IMG_DIR))>0:\n",
    "    evaluate_binary_detector_on_dir(VAL_IMG_DIR, VAL_LBL_DIR, max_imgs=MAX_VAL_IMAGES, iou_thr=EVAL_IOU_THR)\n",
    "else:\n",
    "    print(\"[ê²½ê³ ] valid ì´ë¯¸ì§€ê°€ ë¹„ì–´ ìˆìŒ. trainìœ¼ë¡œ í‰ê°€ ëŒ€ì²´.\")\n",
    "    evaluate_binary_detector_on_dir(TRAIN_IMG_DIR, TRAIN_LBL_DIR, max_imgs=MAX_VAL_IMAGES, iou_thr=EVAL_IOU_THR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974fafc7-b699-456b-b9d7-ba28b08d6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Detector model saved to ./saved_models/\n"
     ]
    }
   ],
   "source": [
    "import joblib, os\n",
    "\n",
    "MODEL_DIR = './saved_models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Binary detector ëª¨ë¸ ì €ì¥ (í™•ë¥  ë³´ì •ëœ ë²„ì „)\n",
    "joblib.dump(clf, os.path.join(MODEL_DIR, 'detector_binary_svm.pkl'))\n",
    "\n",
    "# Scalerë„ ê°™ì´ ì €ì¥í•´ì•¼ í•¨ (ê²€ì¶œ ì‹œ normalization í•„ìš”)\n",
    "joblib.dump(scaler, os.path.join(MODEL_DIR, 'detector_scaler.pkl'))\n",
    "\n",
    "print(\"âœ… Detector model saved to ./saved_models/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (COMP9517)",
   "language": "python",
   "name": "comp9517"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
