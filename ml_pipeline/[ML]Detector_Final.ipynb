{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2033d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "from joblib import dump, load\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported\")\n",
    "#Data paths\n",
    "DATA_DIR      = '../data'\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train', 'images')\n",
    "TRAIN_LBL_DIR = os.path.join(DATA_DIR, 'train', 'labels')\n",
    "VAL_IMG_DIR   = os.path.join(DATA_DIR, 'valid', 'images')\n",
    "VAL_LBL_DIR   = os.path.join(DATA_DIR, 'valid', 'labels')\n",
    "TEST_IMG_DIR  = os.path.join(DATA_DIR, 'test', 'images')\n",
    "TEST_LBL_DIR  = os.path.join(DATA_DIR, 'test', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0b1ea03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보 박스 모듈 on/off =====\n",
    "USE_PREPROC   = False   # 전처리 마스크 기반\n",
    "USE_SLIDING   = False   # 슬라이딩 윈도우\n",
    "USE_EDGE      = True  # 에지/컨투어 기반\n",
    "USE_MSER      = False  # MSER 기반 blob\n",
    "USE_SEG       = False  # 세그멘테이션 기반 (SLIC 등)\n",
    "USE_KP        = False  # 키포인트 클러스터 기반\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "88334d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터\n",
    "# Detection hyperparameters\n",
    "# ============================\n",
    "DET_SCALES        = [0.75, 1.0, 1.25]   # 슬라이딩 윈도우 스케일\n",
    "DET_STRIDE_RATIO  = 0.5                 # 윈도우 크기의 몇 배 간격으로 이동할지\n",
    "DET_SCORE_THRESH  = 0.5                 # SVM decision_function threshold\n",
    "DET_NMS_IOU_THR   = 0.3                 # NMS에서 박스를 지울 IoU 기준\n",
    "# ============================\n",
    "# Hog parameters\n",
    "PATCH_SIZE         = (128, 128)   # (H, W)\n",
    "HOG_ORIENTATIONS   = 9\n",
    "HOG_PIXELS_PER_CELL = (8, 8)\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)\n",
    "HOG_BLOCK_NORM     = 'L2-Hys'\n",
    "HOG_TRANSFORM_SQRT = True\n",
    "# ============================\n",
    "#svm parameters\n",
    "SVM_C            = 1.0\n",
    "SVM_CLASS_WEIGHT = \"balanced\"   # 또는 {0:1.0, 1:1.5} 같은 dict\n",
    "SVM_MAX_ITER     = 5000\n",
    "SVM_RANDOM_STATE = 0\n",
    "# ============================\n",
    "# binary class labels\n",
    "BACKGROUND_LABEL = 0\n",
    "INSECT_LABEL     = 1\n",
    "#patch size for cropping\n",
    "PATCH_SIZE = (128, 128)  # H, W (crop을 이 크기로 리사이즈)\n",
    "# ============================\n",
    "#preprocessing parameters\n",
    "BORDER_PX      = 13     # 테두리 폭(px) - 배경 표본 추출용\n",
    "COLOR_SPACE    = \"LAB\"  # \"LAB\" 권장 (HSV도 가능)\n",
    "COLOR_WEIGHT   = 1.6    # 색 점수 가중치 (↑ 전경을 색차 위주로)\n",
    "EDGE_WEIGHT    = 2.75   # 에지 점수 가중치 (↑ 윤곽 위주로)\n",
    "GAUSS_KSIZE    = 5      # 사전 블러(홀수)\n",
    "CC_CONNECT     = 8      # 연결성(4/8)\n",
    "AREA_MIN_RATIO = 0.03  # 연결요소 최소 면적(이미지 대비) — 잡점 제거\n",
    "AREA_MAX_RATIO = 0.45    # 연결요소 최대 면적 — 배경 덩어리 컷\n",
    "OTSU_BIAS      = 0.00   # Otsu 전에 fused에서 빼는 바이어스(0~0.2 시도)\n",
    "# ============================\n",
    "#data sampling parameters\n",
    "TRAIN_MAX_IMAGES      = 3000    # None이면 train 전부 사용\n",
    "VAL_MAX_IMAGES        = None\n",
    "TEST_MAX_IMAGES       = None\n",
    "MAX_POS_PER_IMG       = 50      # 이미지당 최대 positive 박스 수\n",
    "NEG_POS_RATIO         = 2.0     # 양성 1개당 음성 몇 개\n",
    "NEG_IOU_THR           = 0.1     # 배경 박스가 GT랑 겹치지 않도록 하는 IoU upper bound\n",
    "BG_MAX_ATTEMPTS_FACTOR = 50\n",
    "# ============================\n",
    "#detection(슬라이딩+NMS) parameters\n",
    "SW_SCALES        = (1.0, 1.5, 2.0, 3.0)\n",
    "SW_STRIDE_RATIO  = 0.5\n",
    "CLS_SCORE_THR    = 0.5   # SVM decision_function threshold\n",
    "NMS_IOU_THR      = 0.5\n",
    "EVAL_IOU_THR     = 0.5   # TP 판정용 IoU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "875fc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO format box reader\n",
    "\n",
    "def read_yolo_boxes(label_path: str, img_w: int, img_h: int):\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    if not os.path.exists(label_path):\n",
    "        return boxes, labels\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "\n",
    "            cls = int(float(parts[0]))\n",
    "            xc, yc, w, h = map(float, parts[1:5])\n",
    "\n",
    "            bw = w * img_w\n",
    "            bh = h * img_h\n",
    "            x  = (xc - w / 2.0) * img_w\n",
    "            y  = (yc - h / 2.0) * img_h\n",
    "\n",
    "            x = int(np.clip(x, 0, img_w - 1))\n",
    "            y = int(np.clip(y, 0, img_h - 1))\n",
    "            bw = int(np.clip(bw, 1, img_w - x))\n",
    "            bh = int(np.clip(bh, 1, img_h - y))\n",
    "\n",
    "            boxes.append((x, y, bw, bh))\n",
    "            labels.append(cls)\n",
    "    return boxes, labels\n",
    "\n",
    "#Image listing\n",
    "def list_images(img_dir: str):\n",
    "    exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\",\n",
    "            \"*.JPG\", \"*.JPEG\", \"*.PNG\", \"*.BMP\")\n",
    "    img_paths = []\n",
    "    for ext in exts:\n",
    "        img_paths.extend(glob.glob(os.path.join(img_dir, ext)))\n",
    "    img_paths = sorted(img_paths)\n",
    "    print(f\"[DEBUG] {img_dir} 에서 이미지 {len(img_paths)}개 발견\")\n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5a6070f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch generation + hog\n",
    "def crop_resize_gray(bgr: np.ndarray,\n",
    "                     box: Tuple[int, int, int, int],\n",
    "                     size: Tuple[int, int] = PATCH_SIZE):\n",
    "    x, y, w, h = box\n",
    "    H, W = bgr.shape[:2]\n",
    "\n",
    "    x0 = max(0, x)\n",
    "    y0 = max(0, y)\n",
    "    x1 = min(W, x + w)\n",
    "    y1 = min(H, y + h)\n",
    "\n",
    "    if x0 >= x1 or y0 >= y1:\n",
    "        return None\n",
    "\n",
    "    crop = bgr[y0:y1, x0:x1]\n",
    "    if crop.size == 0:\n",
    "        return None\n",
    "\n",
    "    crop_resized = cv2.resize(crop, (size[1], size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    gray = cv2.cvtColor(crop_resized, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "\n",
    "def extract_hog_feature(gray: np.ndarray):\n",
    "    feat = hog(\n",
    "        gray,\n",
    "        orientations=HOG_ORIENTATIONS,\n",
    "        pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "        cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "        block_norm=HOG_BLOCK_NORM,\n",
    "        transform_sqrt=HOG_TRANSFORM_SQRT,\n",
    "        feature_vector=True\n",
    "    )\n",
    "    return feat.astype(np.float32)\n",
    "\n",
    "\n",
    "def sample_background_boxes(\n",
    "    H: int,\n",
    "    W: int,\n",
    "    gt_boxes: List[Tuple[int,int,int,int]],\n",
    "    num_neg: int,\n",
    "    neg_iou_thr: float = NEG_IOU_THR,\n",
    "    max_attempts_factor: int = BG_MAX_ATTEMPTS_FACTOR\n",
    "):\n",
    "    boxes = []\n",
    "    if num_neg <= 0:\n",
    "        return boxes\n",
    "\n",
    "    max_attempts = max_attempts_factor * num_neg\n",
    "    attempts = 0\n",
    "\n",
    "    while len(boxes) < num_neg and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "\n",
    "        min_size = max(16, min(H, W) // 10)\n",
    "        max_size = max(min_size + 1, min(H, W) // 2)\n",
    "        bw = np.random.randint(min_size, max_size)\n",
    "        bh = np.random.randint(min_size, max_size)\n",
    "        if bw <= 0 or bh <= 0:\n",
    "            continue\n",
    "\n",
    "        x = np.random.randint(0, max(1, W - bw + 1))\n",
    "        y = np.random.randint(0, max(1, H - bh + 1))\n",
    "        box = (x, y, bw, bh)\n",
    "\n",
    "        ious = [iou_xywh(box, g) for g in gt_boxes]\n",
    "        if len(ious) > 0 and max(ious) > neg_iou_thr:\n",
    "            continue\n",
    "\n",
    "        boxes.append(box)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def build_binary_dataset_for_split(\n",
    "    img_dir: str,\n",
    "    lbl_dir: str,\n",
    "    split_name: str = \"train\",\n",
    "    max_images: int = None,\n",
    "    max_pos_per_img: int = MAX_POS_PER_IMG,\n",
    "    neg_pos_ratio: float = NEG_POS_RATIO,\n",
    "    neg_iou_thr: float = NEG_IOU_THR\n",
    "):\n",
    "    \"\"\"\n",
    "    Positive: GT box crop\n",
    "    Negative: GT와 IoU <= neg_iou_thr 인 랜덤 배경 crop\n",
    "    \"\"\"\n",
    "    img_paths = list_images(img_dir)\n",
    "    if max_images is not None:\n",
    "        img_paths = img_paths[:max_images]\n",
    "\n",
    "    if len(img_paths) == 0:\n",
    "        raise RuntimeError(f\"No images found in {img_dir}\")\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    total_pos = 0\n",
    "    total_neg = 0\n",
    "\n",
    "    for img_path in tqdm(img_paths, desc=f\"Build binary HOG dataset @ {split_name}\"):\n",
    "        bgr = cv2.imread(img_path)\n",
    "        if bgr is None:\n",
    "            continue\n",
    "        H, W = bgr.shape[:2]\n",
    "\n",
    "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "        gt_boxes, gt_labels = read_yolo_boxes(label_path, W, H)\n",
    "\n",
    "        # Positive\n",
    "        pos_boxes = gt_boxes\n",
    "        if max_pos_per_img is not None and len(pos_boxes) > max_pos_per_img:\n",
    "            pos_boxes = pos_boxes[:max_pos_per_img]\n",
    "\n",
    "        for box in pos_boxes:\n",
    "            gray = crop_resize_gray(bgr, box)\n",
    "            if gray is None:\n",
    "                continue\n",
    "            feat = extract_hog_feature(gray)\n",
    "            X_list.append(feat)\n",
    "            y_list.append(INSECT_LABEL)\n",
    "            total_pos += 1\n",
    "\n",
    "        # Negative\n",
    "        if neg_pos_ratio > 0:\n",
    "            pos_count_for_neg = len(pos_boxes) if len(pos_boxes) > 0 else (max_pos_per_img or 10)\n",
    "            num_neg_desired = int(pos_count_for_neg * neg_pos_ratio)\n",
    "\n",
    "            bg_boxes = sample_background_boxes(\n",
    "                H, W,\n",
    "                gt_boxes,\n",
    "                num_neg=num_neg_desired,\n",
    "                neg_iou_thr=neg_iou_thr\n",
    "            )\n",
    "\n",
    "            for box in bg_boxes:\n",
    "                gray_bg = crop_resize_gray(bgr, box)\n",
    "                if gray_bg is None:\n",
    "                    continue\n",
    "                feat_bg = extract_hog_feature(gray_bg)\n",
    "                X_list.append(feat_bg)\n",
    "                y_list.append(BACKGROUND_LABEL)\n",
    "                total_neg += 1\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        raise RuntimeError(f\"No samples collected from {img_dir}. Check labels and paths.\")\n",
    "\n",
    "    X = np.vstack(X_list).astype(np.float32)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "\n",
    "    print(f\"[INFO] {split_name} split: 총 샘플 수 = {len(y)}\")\n",
    "    print(f\"[INFO]   - Positive(곤충=1): {total_pos}\")\n",
    "    print(f\"[INFO]   - Negative(배경=0): {total_neg}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def evaluate_patch_split(\n",
    "    clf: LinearSVC,\n",
    "    scaler: StandardScaler,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    split_name: str = \"valid\"\n",
    "):\n",
    "    X_std = scaler.transform(X)\n",
    "    y_pred = clf.predict(X_std)\n",
    "\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    print(f\"\\n[{split_name}] Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    print(f\"\\n[{split_name}] Classification report (0=background, 1=insect):\")\n",
    "    print(classification_report(\n",
    "        y, y_pred,\n",
    "        labels=[0, 1],\n",
    "        target_names=[\"background\", \"insect\"],\n",
    "        digits=4\n",
    "    ))\n",
    "\n",
    "    print(f\"[{split_name}] Confusion matrix (rows=true, cols=pred):\")\n",
    "    print(confusion_matrix(y, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "54833494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepressing based box\n",
    "def _to_colorspace(bgr, mode=\"LAB\"):\n",
    "    mode = mode.upper()\n",
    "    if mode == \"LAB\":\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "    elif mode == \"HSV\":\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"COLOR_SPACE must be 'LAB' or 'HSV'.\")\n",
    "\n",
    "def _border_stats(colimg, border_px):\n",
    "    H, W = colimg.shape[:2]\n",
    "    m = np.zeros((H, W), np.uint8)\n",
    "    m[:border_px,:] = 1; m[-border_px:,:] = 1; m[:,:border_px] = 1; m[:,-border_px:] = 1\n",
    "    samples = colimg[m>0].reshape(-1, colimg.shape[2])\n",
    "    mu  = np.median(samples, axis=0).astype(np.float32)\n",
    "    cov = np.cov(samples.T).astype(np.float32) if len(samples)>=10 else np.eye(colimg.shape[2], dtype=np.float32)\n",
    "    return mu, cov\n",
    "\n",
    "def _mahalanobis(X, mu, cov):\n",
    "    C = cov.shape[0]\n",
    "    inv = np.linalg.inv(cov + 1e-6*np.eye(C, dtype=np.float32))\n",
    "    d = (X - mu).astype(np.float32)\n",
    "    return np.sqrt(np.einsum('...i,ij,...j->...', d, inv, d)).astype(np.float32)\n",
    "\n",
    "def _grad_mag(gray):\n",
    "    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    mag = cv2.magnitude(gx, gy)\n",
    "    mag = mag / (mag.max() + 1e-6)\n",
    "    return mag.astype(np.float32)\n",
    "\n",
    "def _norm01(x):\n",
    "    x = x.astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    return np.zeros_like(x) if mx-mn < 1e-6 else (x-mn)/(mx-mn)\n",
    "\n",
    "def make_fg_mask_simple(bgr):\n",
    "    \"\"\"\n",
    "    텍스처/모폴로지 없이:\n",
    "    - 테두리 배경 통계로 Mahalanobis 색 거리 + Sobel 에지 → 점수 결합 → Otsu\n",
    "    - 작은/너무 큰 연결요소만 면적으로 필터링\n",
    "    \"\"\"\n",
    "    H, W = bgr.shape[:2]\n",
    "    blur = cv2.GaussianBlur(bgr, (GAUSS_KSIZE, GAUSS_KSIZE), 0)\n",
    "\n",
    "    col = _to_colorspace(blur, COLOR_SPACE)\n",
    "    mu, cov = _border_stats(col, BORDER_PX)\n",
    "\n",
    "    dist = _mahalanobis(col.reshape(-1, col.shape[2]), mu, cov).reshape(H, W)\n",
    "    color_score = _norm01(dist)\n",
    "\n",
    "    gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
    "    edge_score = _grad_mag(gray)\n",
    "\n",
    "    fused = COLOR_WEIGHT*color_score + EDGE_WEIGHT*edge_score\n",
    "    fused = _norm01(fused)\n",
    "    if OTSU_BIAS != 0.0:\n",
    "        fused = np.clip(fused - OTSU_BIAS, 0, 1)\n",
    "\n",
    "    fused_u8 = (fused*255).astype(np.uint8)\n",
    "    _, mask = cv2.threshold(fused_u8, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    # 형태학 없이 → 면적 기반 연결요소 필터만\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=int(CC_CONNECT))\n",
    "    out = np.zeros_like(mask)\n",
    "    img_area = H*W\n",
    "    for i in range(1, num):\n",
    "        x,y,w,h,area = stats[i]\n",
    "        if area < AREA_MIN_RATIO*img_area or area > AREA_MAX_RATIO*img_area:\n",
    "            continue\n",
    "        out[labels==i] = 255\n",
    "    return out\n",
    "\n",
    "def propose_boxes_from_mask(\n",
    "    mask,\n",
    "    min_area_ratio=0.001,   # 이미지 대비 최소 면적(노이즈 컷)\n",
    "    max_area_ratio=0.90,    # 이미지 대비 최대 면적(배경 큰 덩어리 컷)\n",
    "    pad=4,                  # 박스 패딩(px)\n",
    "    connectivity=8,         # 연결성(4 또는 8)\n",
    "    merge=True,             # 겹친 박스 병합 여부\n",
    "    merge_iou=0.30          # 병합 임계 IoU\n",
    "):\n",
    "    \"\"\"\n",
    "    전경 마스크(0/255) → 후보 박스 목록 [(x,y,w,h), ...] 생성\n",
    "    - 연결요소 기반 바운딩 박스 추출\n",
    "    - 면적 비율로 1차 필터\n",
    "    - 패딩 부여 후 이미지 경계로 클립\n",
    "    - (옵션) IoU 기준으로 박스 병합\n",
    "    \"\"\"\n",
    "    if mask is None or mask.size == 0:\n",
    "        return []\n",
    "\n",
    "    # 마스크 이진화 보정(0/255 보장)\n",
    "    if mask.dtype != np.uint8:\n",
    "        binm = (mask > 0).astype(np.uint8)\n",
    "    else:\n",
    "        binm = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    H, W = binm.shape[:2]\n",
    "    img_area = H * W\n",
    "    if img_area == 0:\n",
    "        return []\n",
    "\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(binm, connectivity=int(connectivity))\n",
    "    boxes = []\n",
    "    for i in range(1, num):  # 0은 배경\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area < min_area_ratio * img_area or area > max_area_ratio * img_area:\n",
    "            continue\n",
    "\n",
    "        # 패딩\n",
    "        x0 = max(0, x - pad)\n",
    "        y0 = max(0, y - pad)\n",
    "        x1 = min(W - 1, x + w + pad - 1)\n",
    "        y1 = min(H - 1, y + h + pad - 1)\n",
    "\n",
    "        xx, yy = int(x0), int(y0)\n",
    "        ww, hh = int(max(1, x1 - x0 + 1)), int(max(1, y1 - y0 + 1))\n",
    "        boxes.append((xx, yy, ww, hh))\n",
    "\n",
    "    if not merge or len(boxes) <= 1:\n",
    "        boxes.sort(key=lambda b: b[2]*b[3], reverse=True)\n",
    "        return boxes\n",
    "\n",
    "    # ---------------------------\n",
    "    # 간단 병합(높은 IoU 박스 합치기)\n",
    "    # ---------------------------\n",
    "    def _xywh_to_xyxy(b):\n",
    "        x, y, w, h = b\n",
    "        return (x, y, x + w - 1, y + h - 1)\n",
    "\n",
    "    def _xyxy_to_xywh(b):\n",
    "        x1, y1, x2, y2 = b\n",
    "        return (x1, y1, x2 - x1 + 1, y2 - y1 + 1)\n",
    "\n",
    "    def _iou(a, b):\n",
    "        ax1, ay1, ax2, ay2 = a\n",
    "        bx1, by1, bx2, by2 = b\n",
    "        iw = max(0, min(ax2, bx2) - max(ax1, bx1) + 1)\n",
    "        ih = max(0, min(ay2, by2) - max(ay1, by1) + 1)\n",
    "        inter = iw * ih\n",
    "        if inter <= 0:\n",
    "            return 0.0\n",
    "        area_a = (ax2 - ax1 + 1) * (ay2 - ay1 + 1)\n",
    "        area_b = (bx2 - bx1 + 1) * (by2 - by1 + 1)\n",
    "        return inter / float(area_a + area_b - inter + 1e-9)\n",
    "\n",
    "    xyxy = [_xywh_to_xyxy(b) for b in boxes]\n",
    "    changed = True\n",
    "    while changed and len(xyxy) > 1:\n",
    "        changed = False\n",
    "        new_xyxy = []\n",
    "        used = [False] * len(xyxy)\n",
    "\n",
    "        for i in range(len(xyxy)):\n",
    "            if used[i]:\n",
    "                continue\n",
    "            merged = xyxy[i]\n",
    "            used[i] = True\n",
    "            for j in range(i + 1, len(xyxy)):\n",
    "                if used[j]:\n",
    "                    continue\n",
    "                if _iou(merged, xyxy[j]) >= merge_iou:\n",
    "                    # 합집합(바운딩 박스)\n",
    "                    x1 = min(merged[0], xyxy[j][0])\n",
    "                    y1 = min(merged[1], xyxy[j][1])\n",
    "                    x2 = max(merged[2], xyxy[j][2])\n",
    "                    y2 = max(merged[3], xyxy[j][3])\n",
    "                    merged = (x1, y1, x2, y2)\n",
    "                    used[j] = True\n",
    "                    changed = True\n",
    "            new_xyxy.append(merged)\n",
    "        xyxy = new_xyxy\n",
    "\n",
    "    merged_boxes = [_xyxy_to_xywh(b) for b in xyxy]\n",
    "    merged_boxes.sort(key=lambda b: b[2]*b[3], reverse=True)\n",
    "    return merged_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "eec6987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#슬라이딩 윈도우\n",
    "def generate_sliding_window_boxes(\n",
    "    img_h: int,\n",
    "    img_w: int,\n",
    "    base_size: Tuple[int, int] = PATCH_SIZE,\n",
    "    scales: List[float] = DET_SCALES,\n",
    "    stride_ratio: float = DET_STRIDE_RATIO\n",
    ") -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"\n",
    "    멀티스케일 슬라이딩 윈도우로 후보 박스를 생성.\n",
    "    반환: [(x, y, w, h), ...]\n",
    "    \"\"\"\n",
    "    base_h, base_w = base_size\n",
    "    boxes = []\n",
    "\n",
    "    for s in scales:\n",
    "        win_h = int(round(base_h * s))\n",
    "        win_w = int(round(base_w * s))\n",
    "        if win_h <= 0 or win_w <= 0:\n",
    "            continue\n",
    "\n",
    "        stride_y = max(1, int(round(win_h * stride_ratio)))\n",
    "        stride_x = max(1, int(round(win_w * stride_ratio)))\n",
    "\n",
    "        for y in range(0, max(1, img_h - win_h + 1), stride_y):\n",
    "            for x in range(0, max(1, img_w - win_w + 1), stride_x):\n",
    "                boxes.append((x, y, win_w, win_h))\n",
    "\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "01a24db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge / Contour 기반 proposal\n",
    "def propose_boxes_from_edges(\n",
    "    bgr: np.ndarray,\n",
    "    min_area_ratio: float = 0.03,\n",
    "    max_area_ratio: float = 0.45\n",
    ") -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"\n",
    "    Canny 에지 + 컨투어 기반 박스 제안\n",
    "    \"\"\"\n",
    "    H, W = bgr.shape[:2]\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 에지 검출\n",
    "    edges = cv2.Canny(gray_blur, 50, 150)\n",
    "\n",
    "    # 컨투어 추출\n",
    "    contours, _ = cv2.findContours(\n",
    "        edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    boxes = []\n",
    "    img_area = H * W\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = w * h\n",
    "        ratio = area / float(img_area)\n",
    "        if ratio < min_area_ratio or ratio > max_area_ratio:\n",
    "            continue\n",
    "        boxes.append((x, y, w, h))\n",
    "\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "71c4a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSER 기반 proposal\n",
    "def propose_boxes_from_mser(\n",
    "    bgr: np.ndarray,\n",
    "    min_area_ratio: float = 0.0005,\n",
    "    max_area_ratio: float = 0.5\n",
    ") -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"\n",
    "    MSER 기반 후보 박스 생성\n",
    "    \"\"\"\n",
    "    H, W = bgr.shape[:2]\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 1) MSER 객체 생성 (키워드 인자 X)\n",
    "    mser = cv2.MSER_create()\n",
    "\n",
    "    # 2) 파라미터는 setter로 설정\n",
    "    mser.setDelta(5)\n",
    "    mser.setMinArea(int(min_area_ratio * H * W))\n",
    "    mser.setMaxArea(int(max_area_ratio * H * W))\n",
    "\n",
    "    # 3) 영역 검출\n",
    "    regions, _ = mser.detectRegions(gray)\n",
    "\n",
    "    boxes = []\n",
    "    for pts in regions:\n",
    "        x, y, w, h = cv2.boundingRect(pts)\n",
    "        boxes.append((x, y, w, h))\n",
    "\n",
    "    # (선택) 완전히 중복되는 박스 제거\n",
    "    boxes = list({(x, y, w, h) for (x, y, w, h) in boxes})\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "8c67178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#세그멘테이션 기반 proposal (SLIC)\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "def propose_boxes_from_segmentation(\n",
    "    bgr: np.ndarray,\n",
    "    n_segments: int = 200,\n",
    "    compactness: float = 10.0,\n",
    "    min_area_ratio: float = 0.001,\n",
    "    max_area_ratio: float = 0.4\n",
    ") -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"\n",
    "    SLIC superpixel + bounding box 기반 proposal\n",
    "    \"\"\"\n",
    "    H, W = bgr.shape[:2]\n",
    "    img_rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    segments = slic(\n",
    "        img_rgb,\n",
    "        n_segments=n_segments,\n",
    "        compactness=compactness,\n",
    "        start_label=0\n",
    "    )\n",
    "\n",
    "    boxes = []\n",
    "    img_area = H * W\n",
    "    for seg_id in np.unique(segments):\n",
    "        ys, xs = np.where(segments == seg_id)\n",
    "        if ys.size == 0:\n",
    "            continue\n",
    "        y1, y2 = ys.min(), ys.max()\n",
    "        x1, x2 = xs.min(), xs.max()\n",
    "        w = x2 - x1 + 1\n",
    "        h = y2 - y1 + 1\n",
    "        area = w * h\n",
    "        ratio = area / float(img_area)\n",
    "        if ratio < min_area_ratio or ratio > max_area_ratio:\n",
    "            continue\n",
    "        boxes.append((int(x1), int(y1), int(w), int(h)))\n",
    "\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "85d3815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#키포인트 클러스터링 기반 proposal\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def propose_boxes_from_keypoints(\n",
    "    bgr: np.ndarray,\n",
    "    max_corners: int = 500,\n",
    "    quality_level: float = 0.01,\n",
    "    min_distance: float = 5.0,\n",
    "    eps: float = 25.0,\n",
    "    min_samples: int = 5,\n",
    "    min_area_ratio: float = 0.03,\n",
    "    max_area_ratio: float = 0.45\n",
    ") -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"\n",
    "    키포인트(코너) → DBSCAN 클러스터 → bounding box\n",
    "    \"\"\"\n",
    "    H, W = bgr.shape[:2]\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 코너(키포인트) 검출\n",
    "    pts = cv2.goodFeaturesToTrack(\n",
    "        gray,\n",
    "        maxCorners=max_corners,\n",
    "        qualityLevel=quality_level,\n",
    "        minDistance=min_distance\n",
    "    )\n",
    "    if pts is None or len(pts) == 0:\n",
    "        return []\n",
    "\n",
    "    pts = pts.reshape(-1, 2)  # (N, 2)\n",
    "\n",
    "    # 밀도 기반 클러스터링\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(pts)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    boxes = []\n",
    "    img_area = H * W\n",
    "\n",
    "    for lab in np.unique(labels):\n",
    "        if lab == -1:\n",
    "            continue  # noise\n",
    "        cluster_pts = pts[labels == lab]\n",
    "        xs = cluster_pts[:, 0]\n",
    "        ys = cluster_pts[:, 1]\n",
    "        x1, x2 = xs.min(), xs.max()\n",
    "        y1, y2 = ys.min(), ys.max()\n",
    "        w = x2 - x1 + 1\n",
    "        h = y2 - y1 + 1\n",
    "        area = w * h\n",
    "        ratio = area / float(img_area)\n",
    "        if ratio < min_area_ratio or ratio > max_area_ratio:\n",
    "            continue\n",
    "\n",
    "        # 약간 패딩\n",
    "        pad = 4\n",
    "        x1 = max(0, int(x1) - pad)\n",
    "        y1 = max(0, int(y1) - pad)\n",
    "        x2 = min(W - 1, int(x2) + pad)\n",
    "        y2 = min(H - 1, int(y2) + pad)\n",
    "        w = x2 - x1 + 1\n",
    "        h = y2 - y1 + 1\n",
    "\n",
    "        boxes.append((x1, y1, w, h))\n",
    "\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7f5a0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IoU calculation\n",
    "def iou_xywh(box1, box2):\n",
    "    \"\"\"\n",
    "    box: (x, y, w, h) → IoU 계산\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    ax1, ay1, ax2, ay2 = x1, y1, x1 + w1 - 1, y1 + h1 - 1\n",
    "    bx1, by1, bx2, by2 = x2, y2, x2 + w2 - 1, y2 + h2 - 1\n",
    "\n",
    "    iw = max(0, min(ax2, bx2) - max(ax1, bx1) + 1)\n",
    "    ih = max(0, min(ay2, by2) - max(ay1, by1) + 1)\n",
    "    inter = iw * ih\n",
    "    if inter <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    area_a = w1 * h1\n",
    "    area_b = w2 * h2\n",
    "    return inter / float(area_a + area_b - inter + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "724997b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMS 함수 (IoU 기준) final_boxes, final_scores return\n",
    "def nms_xywh(\n",
    "    boxes: List[Tuple[int, int, int, int]],\n",
    "    scores: List[float],\n",
    "    iou_thr: float = DET_NMS_IOU_THR\n",
    ") -> Tuple[List[Tuple[int, int, int, int]], List[float]]:\n",
    "    \"\"\"\n",
    "    간단한 NMS (Non-Maximum Suppression), 박스 포맷은 (x, y, w, h)\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return [], []\n",
    "\n",
    "    boxes = np.array(boxes, dtype=np.float32)\n",
    "    scores = np.array(scores, dtype=np.float32)\n",
    "\n",
    "    order = scores.argsort()[::-1]  # 점수 내림차순 인덱스\n",
    "    keep_indices = []\n",
    "\n",
    "    while len(order) > 0:\n",
    "        i = order[0]\n",
    "        keep_indices.append(int(i))\n",
    "\n",
    "        if len(order) == 1:\n",
    "            break\n",
    "\n",
    "        rest = order[1:]\n",
    "        i_box = boxes[i]\n",
    "\n",
    "        ious = []\n",
    "        for j in rest:\n",
    "            j_box = boxes[j]\n",
    "            ious.append(iou_xywh(tuple(i_box), tuple(j_box)))\n",
    "        ious = np.array(ious, dtype=np.float32)\n",
    "\n",
    "        # IoU가 threshold보다 큰 애들은 제거\n",
    "        remaining = rest[ious <= iou_thr]\n",
    "        order = remaining\n",
    "\n",
    "    final_boxes = [tuple(boxes[i].astype(int)) for i in keep_indices]\n",
    "    final_scores = [float(scores[i]) for i in keep_indices]\n",
    "    return final_boxes, final_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1eeae0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#후보 박스 생성\n",
    "def get_candidate_boxes(\n",
    "    bgr: np.ndarray,\n",
    "    use_preproc: bool = True,\n",
    "    use_sliding: bool = True,\n",
    "    use_edge: bool = False,\n",
    "    use_mser: bool = False,\n",
    "    use_seg: bool = False,\n",
    "    use_kp: bool = False\n",
    ") -> List[Tuple[int, int, int, int]]:\n",
    "    \"\"\"\n",
    "    한 장의 이미지에서\n",
    "    - 전처리 기반 후보\n",
    "    - 슬라이딩 윈도우 후보\n",
    "    를 모두 모아서 반환.\n",
    "    \"\"\"\n",
    "    H, W = bgr.shape[:2]\n",
    "    all_boxes: List[Tuple[int, int, int, int]] = []\n",
    "\n",
    "    # 1) 전처리 기반 후보\n",
    "    if use_preproc:\n",
    "        fg_mask = make_fg_mask_simple(bgr)\n",
    "        boxes_fg = propose_boxes_from_mask(\n",
    "            fg_mask,\n",
    "            min_area_ratio=0.001,\n",
    "            max_area_ratio=0.9,\n",
    "            pad=4,\n",
    "            connectivity=8,\n",
    "            merge=True,\n",
    "            merge_iou=0.30\n",
    "        )\n",
    "        all_boxes.extend(boxes_fg)\n",
    "\n",
    "    # 2) 슬라이딩 윈도우 후보\n",
    "    if use_sliding:\n",
    "        boxes_sw = generate_sliding_window_boxes(\n",
    "            H, W,\n",
    "            base_size=PATCH_SIZE,\n",
    "            scales=SW_SCALES,\n",
    "            stride_ratio=SW_STRIDE_RATIO\n",
    "        )\n",
    "        all_boxes.extend(boxes_sw)\n",
    "\n",
    "    \n",
    "    # 3) 에지/컨투어 기반\n",
    "    if use_edge:\n",
    "        boxes_edge = propose_boxes_from_edges(bgr)\n",
    "        all_boxes.extend(boxes_edge)\n",
    "\n",
    "    # 4) MSER 기반\n",
    "    if use_mser:\n",
    "        boxes_mser = propose_boxes_from_mser(bgr)\n",
    "        all_boxes.extend(boxes_mser)\n",
    "\n",
    "    # 5) 세그멘테이션 기반\n",
    "    if use_seg:\n",
    "        boxes_seg = propose_boxes_from_segmentation(bgr)\n",
    "        all_boxes.extend(boxes_seg)\n",
    "\n",
    "    # 6) 키포인트 클러스터 기반\n",
    "    if use_kp:\n",
    "        boxes_kp = propose_boxes_from_keypoints(bgr)\n",
    "        all_boxes.extend(boxes_kp)\n",
    "\n",
    "    # 완전히 동일한 박스 제거 (그냥 set 써도 됨)\n",
    "    all_boxes = list({(x, y, w, h) for (x, y, w, h) in all_boxes})\n",
    "    return all_boxes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "37af1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#후보 박스 기반 hog,svm\n",
    "def compute_scores_for_boxes(\n",
    "    bgr: np.ndarray,\n",
    "    boxes: List[Tuple[int, int, int, int]],\n",
    "    scaler: StandardScaler,\n",
    "    svm: LinearSVC\n",
    ") -> Tuple[List[Tuple[int, int, int, int]], np.ndarray]:\n",
    "    \"\"\"\n",
    "    주어진 후보 박스들에 대해:\n",
    "      - crop + resize + gray\n",
    "      - HOG 특징 추출\n",
    "      - StandardScaler 변환\n",
    "      - SVM decision_function 점수 계산\n",
    "    을 수행하고,\n",
    "      (유효한 박스 리스트, 각 박스에 대한 점수 배열)\n",
    "    을 반환.\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    valid_boxes: List[Tuple[int, int, int, int]] = []\n",
    "\n",
    "    for box in boxes:\n",
    "        gray = crop_resize_gray(bgr, box, size=PATCH_SIZE)\n",
    "        if gray is None:\n",
    "            continue\n",
    "        feat = extract_hog_feature(gray)\n",
    "        feats.append(feat)\n",
    "        valid_boxes.append(box)\n",
    "\n",
    "    if len(feats) == 0:\n",
    "        return [], np.array([])\n",
    "\n",
    "    X = np.vstack(feats).astype(np.float32)\n",
    "    X_std = scaler.transform(X)\n",
    "    scores = svm.decision_function(X_std)\n",
    "\n",
    "    return valid_boxes, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "484db957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#점수 기준 1차 필터링 + NMS\n",
    "def filter_boxes_by_score(\n",
    "    boxes: List[Tuple[int, int, int, int]],\n",
    "    scores: np.ndarray,\n",
    "    score_thr: float\n",
    ") -> Tuple[List[Tuple[int, int, int, int]], np.ndarray]:\n",
    "    \"\"\"\n",
    "    SVM 점수가 score_thr 이상인 박스만 남긴다.\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0 or scores.size == 0:\n",
    "        return [], np.array([])\n",
    "\n",
    "    keep_idx = np.where(scores >= score_thr)[0]\n",
    "    if len(keep_idx) == 0:\n",
    "        return [], np.array([])\n",
    "\n",
    "    boxes_pos = [boxes[i] for i in keep_idx]\n",
    "    scores_pos = scores[keep_idx]\n",
    "    return boxes_pos, scores_pos\n",
    "\n",
    "# 이미 정의되어 있는 nms_xywh 사용:\n",
    "    final_boxes, final_scores = nms_xywh(\n",
    "        List[Tuple[int, int, int, int]],\n",
    "        List[float],\n",
    "        float = DET_NMS_IOU_THR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "af53d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#디텍션\n",
    "def detect_in_image(\n",
    "    bgr: np.ndarray,\n",
    "    scaler: StandardScaler,\n",
    "    svm: LinearSVC,\n",
    "    use_preproc: bool = USE_PREPROC,\n",
    "    use_sliding: bool = USE_SLIDING,\n",
    "    use_edge: bool = USE_EDGE,\n",
    "    use_mser: bool = USE_MSER,\n",
    "    use_seg: bool = USE_SEG,\n",
    "    use_kp: bool = USE_KP\n",
    "):\n",
    "    \"\"\"\n",
    "    한 장의 BGR 이미지에 대해:\n",
    "      1) 후보 박스 생성 (preproc + sliding)\n",
    "      2) HOG + SVM 점수 계산\n",
    "      3) 점수 threshold로 1차 필터링\n",
    "      4) NMS로 중복 제거\n",
    "      → 최종 박스 및 점수 반환\n",
    "    \"\"\"\n",
    "    # 1) 후보 박스 생성\n",
    "    all_boxes = get_candidate_boxes(\n",
    "        bgr,\n",
    "        use_preproc=use_preproc,\n",
    "        use_sliding=use_sliding,\n",
    "        use_edge=use_edge,\n",
    "        use_mser=use_mser,\n",
    "        use_seg=use_seg,\n",
    "        use_kp=use_kp\n",
    "    )\n",
    "\n",
    "    if len(all_boxes) == 0:\n",
    "        return [], np.array([])\n",
    "\n",
    "    # 2) 후보 박스에 대한 SVM 점수 계산\n",
    "    valid_boxes, scores = compute_scores_for_boxes(\n",
    "        bgr, all_boxes, scaler, svm\n",
    "    )\n",
    "    if len(valid_boxes) == 0:\n",
    "        return [], np.array([])\n",
    "\n",
    "    # 3) 분류 임계값으로 1차 필터링\n",
    "    boxes_pos, scores_pos = filter_boxes_by_score(\n",
    "        valid_boxes, scores, CLS_SCORE_THR\n",
    "    )\n",
    "    if len(boxes_pos) == 0:\n",
    "        return [], np.array([])\n",
    "\n",
    "    # 4) NMS 적용\n",
    "    final_boxes, final_scores = nms_xywh(\n",
    "        boxes_pos, scores_pos, iou_thr=NMS_IOU_THR\n",
    "    )\n",
    "\n",
    "    return final_boxes, final_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "9203dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mAP 계산 함수\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------\n",
    "# AP 계산용 헬퍼 (단일 클래스, IoU=EVAL_IOU_THR 고정)\n",
    "# --------------------------------------------------\n",
    "def compute_ap(scores: list[float], tp_flags: list[int], num_gt: int) -> float:\n",
    "    \"\"\"\n",
    "    scores: 각 detection의 confidence 점수 리스트\n",
    "    tp_flags: 각 detection이 TP면 1, FP면 0\n",
    "    num_gt: 전체 GT box 개수\n",
    "    \"\"\"\n",
    "    if num_gt == 0 or len(scores) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    scores_np = np.array(scores, dtype=np.float32)\n",
    "    tp_np     = np.array(tp_flags, dtype=np.int32)\n",
    "\n",
    "    # 점수 내림차순 정렬\n",
    "    order = np.argsort(scores_np)[::-1]\n",
    "    scores_np = scores_np[order]\n",
    "    tp_np     = tp_np[order]\n",
    "\n",
    "    fp_np = 1 - tp_np\n",
    "\n",
    "    tp_cum = np.cumsum(tp_np)\n",
    "    fp_cum = np.cumsum(fp_np)\n",
    "\n",
    "    recall    = tp_cum / (num_gt + 1e-9)\n",
    "    precision = tp_cum / (tp_cum + fp_cum + 1e-9)\n",
    "\n",
    "    # VOC 스타일: precision을 뒤에서부터 누적 최대값으로 보정\n",
    "    for i in range(len(precision) - 2, -1, -1):\n",
    "        precision[i] = max(precision[i], precision[i + 1])\n",
    "\n",
    "    # recall이 변하는 구간마다 면적 적분\n",
    "    ap = 0.0\n",
    "    prev_r = 0.0\n",
    "    for r, p in zip(recall, precision):\n",
    "        if r > prev_r:\n",
    "            ap += (r - prev_r) * p\n",
    "            prev_r = r\n",
    "\n",
    "    return float(ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8007941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#디텍터 평가 TP/FP/FN 기반 + AP/mAP 계산\n",
    "def eval_detector_on_split(\n",
    "    img_dir: str,\n",
    "    lbl_dir: str,\n",
    "    scaler: StandardScaler,\n",
    "    svm: LinearSVC,\n",
    "    split_name: str = \"valid\",\n",
    "    max_images: int = None,\n",
    "    det_kwargs: dict | None = None,\n",
    "):\n",
    "    if det_kwargs is None:\n",
    "        det_kwargs = {}\n",
    "\n",
    "    img_paths = list_images(img_dir)\n",
    "    if max_images is not None:\n",
    "        img_paths = img_paths[:max_images]\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # mAP 계산용: 전체 detection에 대한 점수 / TP 여부 저장\n",
    "    all_scores = []\n",
    "    all_tp_flags = []\n",
    "\n",
    "    for img_path in tqdm(img_paths, desc=f\"Eval detector @ {split_name}\"):\n",
    "        bgr = cv2.imread(img_path)\n",
    "        if bgr is None:\n",
    "            continue\n",
    "        H, W = bgr.shape[:2]\n",
    "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "        gt_boxes, gt_labels = read_yolo_boxes(label_path, W, H)\n",
    "\n",
    "        # 디텍션 수행 (옵션들 전달)\n",
    "        pred_boxes, pred_scores = detect_in_image(\n",
    "            bgr,\n",
    "            scaler,\n",
    "            svm,\n",
    "            **det_kwargs\n",
    "        )\n",
    "\n",
    "        used_gt = [False] * len(gt_boxes)\n",
    "\n",
    "        # mAP를 위해, 한 이미지 안에서는 점수 내림차순으로 매칭\n",
    "        if len(pred_boxes) > 0:\n",
    "            order = np.argsort(pred_scores)[::-1]\n",
    "        else:\n",
    "            order = []\n",
    "\n",
    "        for idx in order:\n",
    "            pb = pred_boxes[idx]\n",
    "            score = float(pred_scores[idx])\n",
    "\n",
    "            best_iou = 0.0\n",
    "            best_idx = -1\n",
    "            for gi, gb in enumerate(gt_boxes):\n",
    "                if used_gt[gi]:\n",
    "                    continue\n",
    "                iou = iou_xywh(pb, gb)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_idx = gi\n",
    "\n",
    "            if best_iou >= EVAL_IOU_THR and best_idx >= 0:\n",
    "                TP += 1\n",
    "                used_gt[best_idx] = True\n",
    "                is_tp = 1\n",
    "            else:\n",
    "                FP += 1\n",
    "                is_tp = 0\n",
    "\n",
    "            # 전체 리스트에 추가 (mAP 계산용)\n",
    "            all_scores.append(score)\n",
    "            all_tp_flags.append(is_tp)\n",
    "\n",
    "        # 매칭되지 않은 GT는 FN\n",
    "        for gi, used in enumerate(used_gt):\n",
    "            if not used:\n",
    "                FN += 1\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-9)\n",
    "    recall    = TP / (TP + FN + 1e-9)\n",
    "    f1        = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "    # 전체 GT 수 = TP + FN\n",
    "    total_gt = TP + FN\n",
    "    ap = compute_ap(all_scores, all_tp_flags, total_gt)\n",
    "\n",
    "    print(f\"\\n[{split_name}] Detection results (IoU >= {EVAL_IOU_THR}):\")\n",
    "    print(f\"TP={TP}, FP={FP}, FN={FN}\")\n",
    "    print(f\"Precision={precision:.4f}, Recall={recall:.4f}, F1-score={f1:.4f}\")\n",
    "    print(f\"mAP@{EVAL_IOU_THR:.2f} (single-class AP) = {ap:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b2044cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 끝난 뒤, 한 번에 여러 config를 돌리는 함수\n",
    "from itertools import product\n",
    "\n",
    "def run_detector_ablation(\n",
    "    scaler: StandardScaler,\n",
    "    svm: LinearSVC,\n",
    "    img_dir: str = VAL_IMG_DIR,\n",
    "    lbl_dir: str = VAL_LBL_DIR,\n",
    "    max_images: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    여러 후보 생성 조합을 자동으로 돌려보며 성능 비교.\n",
    "    \"\"\"\n",
    "    # 사용할 모듈 이름과 순서\n",
    "    modules = [\"preproc\", \"sliding\", \"edge\", \"mser\", \"seg\", \"kp\"]\n",
    "\n",
    "    # 실험해볼 조합들(예: 수동 버전) -------------------------\n",
    "    configs = [\n",
    "        (\"preproc_only\",   dict(use_preproc=True,  use_sliding=False, use_edge=False, use_mser=False, use_seg=False, use_kp=False)),\n",
    "       # (\"sliding_only\",   dict(use_preproc=False, use_sliding=True,  use_edge=False, use_mser=False, use_seg=False, use_kp=False)),\n",
    "       # (\"mser_only\",      dict(use_preproc=False, use_sliding=False, use_edge=False, use_mser=True,  use_seg=False, use_kp=False)),\n",
    "       # (\"seg_only\",       dict(use_preproc=False, use_sliding=False, use_edge=False, use_mser=False, use_seg=True,  use_kp=False)),\n",
    "       # (\"kp_only\",        dict(use_preproc=False, use_sliding=False, use_edge=False, use_mser=False, use_seg=False, use_kp=True)),\n",
    "       # (\"preproc+mser\",dict(use_preproc=True,  use_sliding=False,  use_edge=False, use_mser=True, use_seg=False, use_kp=False)),\n",
    "       # (\"preproc+seg\",   dict(use_preproc=True,  use_sliding=False, use_edge=False,  use_mser=False, use_seg=True, use_kp=False)),\n",
    "       # (\"all_modules\",    dict(use_preproc=True,  use_sliding=True,  use_edge=True,  use_mser=True,  use_seg=True,  use_kp=True)),\n",
    "    ]\n",
    "\n",
    "    # 만약 2^6 모든 조합을 다 돌리고 싶으면 위 configs 대신 아래 자동 생성 사용 가능\n",
    "    # configs = []\n",
    "    # for bits in product([0, 1], repeat=len(modules)):\n",
    "    #     if sum(bits) == 0:\n",
    "    #         continue  # 아무 모듈도 안 쓰는 조합은 스킵\n",
    "    #     name_parts = [m for m, b in zip(modules, bits) if b]\n",
    "    #     name = \"+\".join(name_parts)\n",
    "    #     cfg = dict(\n",
    "    #         use_preproc=bool(bits[0]),\n",
    "    #         use_sliding=bool(bits[1]),\n",
    "    #         use_edge=bool(bits[2]),\n",
    "    #         use_mser=bool(bits[3]),\n",
    "    #         use_seg=bool(bits[4]),\n",
    "    #         use_kp=bool(bits[5]),\n",
    "    #     )\n",
    "    #     configs.append((name, cfg))\n",
    "\n",
    "    # 실제 루프\n",
    "    for cfg_name, det_kwargs in configs:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"=== Ablation config: {cfg_name} ===\")\n",
    "        print(\"  det_kwargs:\", det_kwargs)\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        eval_detector_on_split(\n",
    "            img_dir,\n",
    "            lbl_dir,\n",
    "            scaler,\n",
    "            svm,\n",
    "            split_name=f\"valid_{cfg_name}\",\n",
    "            max_images=max_images,\n",
    "            det_kwargs=det_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "60c44240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1) Train binary HOG dataset 생성 ===\n",
      "[DEBUG] ../data/train/images 에서 이미지 11502개 발견\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build binary HOG dataset @ train: 100%|██████████| 3000/3000 [00:35<00:00, 83.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train split: 총 샘플 수 = 13727\n",
      "[INFO]   - Positive(곤충=1): 4577\n",
      "[INFO]   - Negative(배경=0): 9150\n",
      "\n",
      "=== 2) Valid binary HOG dataset 생성 ===\n",
      "[DEBUG] ../data/valid/images 에서 이미지 1095개 발견\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build binary HOG dataset @ valid: 100%|██████████| 1095/1095 [00:10<00:00, 105.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] valid split: 총 샘플 수 = 4023\n",
      "[INFO]   - Positive(곤충=1): 1341\n",
      "[INFO]   - Negative(배경=0): 2682\n",
      "\n",
      "=== 4) StandardScaler 학습 ===\n",
      "\n",
      "=== 5) Linear SVM (이진 분류: insect vs background) 학습 ===\n",
      "→ SVM 학습 완료\n",
      "\n",
      "[train] Accuracy: 100.00%\n",
      "\n",
      "[train] Classification report (0=background, 1=insect):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background     1.0000    1.0000    1.0000      9150\n",
      "      insect     1.0000    1.0000    1.0000      4577\n",
      "\n",
      "    accuracy                         1.0000     13727\n",
      "   macro avg     1.0000    1.0000    1.0000     13727\n",
      "weighted avg     1.0000    1.0000    1.0000     13727\n",
      "\n",
      "[train] Confusion matrix (rows=true, cols=pred):\n",
      "[[9150    0]\n",
      " [   0 4577]]\n",
      "\n",
      "[valid] Accuracy: 82.28%\n",
      "\n",
      "[valid] Classification report (0=background, 1=insect):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background     0.8525    0.8878    0.8698      2682\n",
      "      insect     0.7553    0.6928    0.7227      1341\n",
      "\n",
      "    accuracy                         0.8228      4023\n",
      "   macro avg     0.8039    0.7903    0.7962      4023\n",
      "weighted avg     0.8201    0.8228    0.8207      4023\n",
      "\n",
      "[valid] Confusion matrix (rows=true, cols=pred):\n",
      "[[2381  301]\n",
      " [ 412  929]]\n",
      "\n",
      "=== 6) Detector ablation on VALID set ===\n",
      "\n",
      "============================================================\n",
      "=== Ablation config: preproc_only ===\n",
      "  det_kwargs: {'use_preproc': True, 'use_sliding': False, 'use_edge': False, 'use_mser': False, 'use_seg': False, 'use_kp': False}\n",
      "============================================================\n",
      "[DEBUG] ../data/valid/images 에서 이미지 1095개 발견\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval detector @ valid_preproc_only: 100%|██████████| 200/200 [00:05<00:00, 34.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[valid_preproc_only] Detection results (IoU >= 0.5):\n",
      "TP=109, FP=51, FN=177\n",
      "Precision=0.6812, Recall=0.3811, F1-score=0.4888\n",
      "mAP@0.50 (single-class AP) = 0.3010\n",
      "\n",
      "[INFO] scaler_detector.joblib / svm_detector.joblib 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#메인: 훈련 → 저장 → 디텍션 평가\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # ----- 5-1. 패치 데이터셋 생성 -----\n",
    "    print(\"\\n=== 1) Train binary HOG dataset 생성 ===\")\n",
    "    X_train, y_train = build_binary_dataset_for_split(\n",
    "        TRAIN_IMG_DIR,\n",
    "        TRAIN_LBL_DIR,\n",
    "        split_name=\"train\",\n",
    "        max_images=TRAIN_MAX_IMAGES,\n",
    "        max_pos_per_img=MAX_POS_PER_IMG,\n",
    "        neg_pos_ratio=NEG_POS_RATIO,\n",
    "        neg_iou_thr=NEG_IOU_THR\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== 2) Valid binary HOG dataset 생성 ===\")\n",
    "    X_val, y_val = build_binary_dataset_for_split(\n",
    "        VAL_IMG_DIR,\n",
    "        VAL_LBL_DIR,\n",
    "        split_name=\"valid\",\n",
    "        max_images=VAL_MAX_IMAGES,\n",
    "        max_pos_per_img=MAX_POS_PER_IMG,\n",
    "        neg_pos_ratio=NEG_POS_RATIO,\n",
    "        neg_iou_thr=NEG_IOU_THR\n",
    "    )\n",
    "\n",
    "    # 필요하면 test patch dataset 도 생성 가능\n",
    "    # print(\"\\n=== 3) Test binary HOG dataset 생성 ===\")\n",
    "    # X_test, y_test = build_binary_dataset_for_split(\n",
    "    #     TEST_IMG_DIR,\n",
    "    #     TEST_LBL_DIR,\n",
    "    #     split_name=\"test\",\n",
    "    #     max_images=TEST_MAX_IMAGES,\n",
    "    #     max_pos_per_img=MAX_POS_PER_IMG,\n",
    "    #     neg_pos_ratio=NEG_POS_RATIO,\n",
    "    #     neg_iou_thr=NEG_IOU_THR\n",
    "    # )\n",
    "\n",
    "    # ----- 5-2. SVM 학습 -----\n",
    "    print(\"\\n=== 4) StandardScaler 학습 ===\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "    print(\"\\n=== 5) Linear SVM (이진 분류: insect vs background) 학습 ===\")\n",
    "    svm = LinearSVC(\n",
    "        C=SVM_C,\n",
    "        class_weight=SVM_CLASS_WEIGHT,\n",
    "        max_iter=SVM_MAX_ITER,\n",
    "        random_state=SVM_RANDOM_STATE\n",
    "    )\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    print(\"→ SVM 학습 완료\")\n",
    "\n",
    "    # ----- 5-3. 패치 수준 성능 확인 -----\n",
    "    evaluate_patch_split(svm, scaler, X_train, y_train, split_name=\"train\")\n",
    "    evaluate_patch_split(svm, scaler, X_val,   y_val,   split_name=\"valid\")\n",
    "\n",
    "    # 여기서 Ablation 실행\n",
    "    print(\"\\n=== 6) Detector ablation on VALID set ===\")\n",
    "    run_detector_ablation(\n",
    "        scaler,\n",
    "        svm,\n",
    "        img_dir=VAL_IMG_DIR,\n",
    "        lbl_dir=VAL_LBL_DIR,\n",
    "        max_images=200\n",
    "    )\n",
    "    # ----- 5-4. 모델 저장 -----\n",
    "    dump(scaler, \"scaler_detector.joblib\")\n",
    "    dump(svm,    \"svm_detector.joblib\")\n",
    "    print(\"\\n[INFO] scaler_detector.joblib / svm_detector.joblib 저장 완료\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
