{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aaa47b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b37c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea572e",
   "metadata": {},
   "source": [
    "#### Data  path configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = Path('../data')\n",
    "train_dir = base_dir / 'train'\n",
    "test_dir = base_dir / 'test'\n",
    "validation_dir = base_dir / 'valid'\n",
    "\n",
    "classes = [ \"Ants\",\n",
    "    \"Bees\",\n",
    "    \"Beetles\",\n",
    "    \"Caterpillars\",\n",
    "    \"Earthworms\",\n",
    "    \"Earwigs\",\n",
    "    \"Grasshoppers\",\n",
    "    \"Moths\",\n",
    "    \"Slugs\",\n",
    "    \"Snails\",\n",
    "    \"Wasps\",\n",
    "    \"Weevils\"]\n",
    " \n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256b3b9",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02700289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yolo_label(label_path):\n",
    "    boxes = []\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        return boxes\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split()\n",
    "                class_id = int(parts[0])\n",
    "                x_center = float(parts[1])\n",
    "                y_center = float(parts[2])\n",
    "                width = float(parts[3])\n",
    "                height = float(parts[4])\n",
    "                boxes.append([class_id, x_center, y_center, width, height])\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "def yolo_to_bbox(x_center, y_center, width, height, img_width, img_height):\n",
    "    x_center_abs = x_center * img_width\n",
    "    y_center_abs = y_center * img_height\n",
    "    width_abs = width * img_width\n",
    "    height_abs = height * img_height\n",
    "    \n",
    "    x_min = int(x_center_abs - width_abs / 2)\n",
    "    y_min = int(y_center_abs - height_abs / 2)\n",
    "    x_max = int(x_center_abs + width_abs / 2)\n",
    "    y_max = int(y_center_abs + height_abs / 2)\n",
    "    \n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "\n",
    "def crop_object_from_image(image, bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    x_min = max(0, x_min)\n",
    "    y_min = max(0, y_min)\n",
    "    x_max = min(w, x_max)\n",
    "    y_max = min(h, y_max)\n",
    "    \n",
    "    cropped = image[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    if cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
    "        return None\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "def load_yolo_dataset(data_dir, max_samples=None, use_full_image=False):\n",
    "    images_dir = data_dir / 'images'\n",
    "    labels_dir = data_dir / 'labels'\n",
    "    \n",
    "    print(f\"Loading data from {data_dir}...\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    bboxes = []\n",
    "    \n",
    "    image_files = sorted(list(images_dir.glob('*.jpg')))\n",
    "    \n",
    "    if max_samples:\n",
    "        image_files = image_files[:max_samples]\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "           \n",
    "        label_path = labels_dir / (img_path.stem + '.txt')\n",
    "        \n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "        \n",
    "        boxes = parse_yolo_label(label_path)\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            continue\n",
    "        \n",
    "        for box in boxes:\n",
    "            class_id, x_c, y_c, w, h = box\n",
    "            \n",
    "            if class_id >= num_classes:\n",
    "                continue  \n",
    "            \n",
    "            bbox = yolo_to_bbox(x_c, y_c, w, h, img_width, img_height)\n",
    "            \n",
    "            if use_full_image:\n",
    "                cropped = img\n",
    "            else:\n",
    "                cropped = crop_object_from_image(img, bbox)\n",
    "                \n",
    "                if cropped is None:\n",
    "                    continue\n",
    "            \n",
    "            images.append(cropped)\n",
    "            labels.append(classes[class_id])\n",
    "            bboxes.append(bbox)\n",
    "    \n",
    "    print(f\"Loaded {len(images)} objects from {len(image_files)} images\")\n",
    "    \n",
    "    return images, labels, bboxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541722c",
   "metadata": {},
   "source": [
    "#### HOG Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HOGFeatureExtractor:\n",
    "    def __init__(self, image_size=(128, 128), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "        self.image_size = image_size\n",
    "        self.hog_params = {\n",
    "            'orientations': orientations,\n",
    "            'pixels_per_cell': pixels_per_cell,\n",
    "            'cells_per_block': cells_per_block,\n",
    "            'block_norm': 'L2-Hys',\n",
    "            'channel_axis': None\n",
    "        }\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        if len(image.shape) ==3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "\n",
    "        resized = cv2.resize(gray, self.image_size)\n",
    "        return resized\n",
    "    \n",
    "    def extract_features(self, images):\n",
    "        single_image = False\n",
    "        if not isinstance(images, list):\n",
    "            images = [images]\n",
    "            single_image = True \n",
    "        \n",
    "        features_list = []\n",
    "        iterator = tqdm(images, desc=\"Extracting HOG\")\n",
    "\n",
    "        for img in images:\n",
    "            preprocessed = self.preprocess_image(img)\n",
    "            feature = hog(preprocessed, visualize=False, **self.hog_params)\n",
    "            features_list.append(feature)\n",
    "        \n",
    "        features = np.array(features_list)\n",
    "\n",
    "        return features[0] if single_image else features\n",
    "\n",
    "    def visualize(self, image):\n",
    "        preprocessed = self.preprocess_image(image)\n",
    "        \n",
    "        hog_params_viz = self.hog_params.copy()\n",
    "        \n",
    "        features, hog_image = hog(\n",
    "            preprocessed, \n",
    "            visualize=True, \n",
    "            **hog_params_viz\n",
    "        )\n",
    "        \n",
    "        hog_image = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "        \n",
    "        return features, hog_image, preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31fa32",
   "metadata": {},
   "source": [
    "#### SVM Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e05cbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SVMClassifier:\n",
    "    def __init__(self, kernel='rbf', C=1.0, gamma='scale'):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "        self.training_time = None\n",
    "        self.testing_time = None\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(f\"Training SVM (kernel={self.kernel}, C={self.C})...\")\n",
    "        print(f\"Training samples: {len(X_train)}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Feature scaling (fit on training data)\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        # Label encoding\n",
    "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
    "        \n",
    "        # Check class distribution\n",
    "        unique, counts = np.unique(y_train_encoded, return_counts=True)\n",
    "        print(f\"   Classes: {len(unique)}, Distribution: {dict(zip(unique, counts))}\")\n",
    "        \n",
    "        # SVM training\n",
    "        self.model = SVC(\n",
    "            kernel=self.kernel,\n",
    "            C=self.C,\n",
    "            gamma=self.gamma,\n",
    "            probability=True,  \n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        self.model.fit(X_train_scaled, y_train_encoded)\n",
    "        \n",
    "        self.training_time = time.time() - start_time\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Training completed in {self.training_time:.2f} seconds\")\n",
    "        print(f\"Support vectors: {self.model.n_support_}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        y_pred_encoded = self.model.predict(X_test_scaled)\n",
    "        return self.label_encoder.inverse_transform(y_pred_encoded)\n",
    "    \n",
    "    def predict_prob(self, X_test):\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        return self.model.predict_prob(X_test_scaled)\n",
    "\n",
    "    def evaluate(self, X_test, y_test, dataset_name='Test'):\n",
    "        print(f\"Evaluating on {dataset_name} set...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_test_encoded = self.label_encoder.transform(y_test)\n",
    "        y_pred_encoded = self.label_encoder.transform(y_pred)\n",
    "\n",
    "        pass #do it later.. (nov 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43d449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (COMP9517)",
   "language": "python",
   "name": "comp9517"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
