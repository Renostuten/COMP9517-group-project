{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aaa47b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b37c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea572e",
   "metadata": {},
   "source": [
    "#### Data  path configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5cdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = Path('../data')\n",
    "train_dir = base_dir / 'train'\n",
    "test_dir = base_dir / 'test'\n",
    "validation_dir = base_dir / 'valid'\n",
    "\n",
    "classes = [ \"Ants\",\n",
    "    \"Bees\",\n",
    "    \"Beetles\",\n",
    "    \"Caterpillars\",\n",
    "    \"Earthworms\",\n",
    "    \"Earwigs\",\n",
    "    \"Grasshoppers\",\n",
    "    \"Moths\",\n",
    "    \"Slugs\",\n",
    "    \"Snails\",\n",
    "    \"Wasps\",\n",
    "    \"Weevils\"]\n",
    " \n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256b3b9",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02700289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yolo_label(label_path):\n",
    "    boxes = []\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        return boxes\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split()\n",
    "                class_id = int(parts[0])\n",
    "                x_center = float(parts[1])\n",
    "                y_center = float(parts[2])\n",
    "                width = float(parts[3])\n",
    "                height = float(parts[4])\n",
    "                boxes.append([class_id, x_center, y_center, width, height])\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "def yolo_to_bbox(x_center, y_center, width, height, img_width, img_height):\n",
    "    x_center_abs = x_center * img_width\n",
    "    y_center_abs = y_center * img_height\n",
    "    width_abs = width * img_width\n",
    "    height_abs = height * img_height\n",
    "    \n",
    "    x_min = int(x_center_abs - width_abs / 2)\n",
    "    y_min = int(y_center_abs - height_abs / 2) \n",
    "    x_max = int(x_center_abs + width_abs / 2)\n",
    "    y_max = int(y_center_abs + height_abs / 2)\n",
    "    \n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "\n",
    "def crop_object_from_image(image, bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    x_min = max(0, x_min)\n",
    "    y_min = max(0, y_min)\n",
    "    x_max = min(w, x_max)\n",
    "    y_max = min(h, y_max)\n",
    "    \n",
    "    cropped = image[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    if cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
    "        return None\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "def load_yolo_dataset(data_dir, max_samples=None, use_full_image=False):\n",
    "    images_dir = data_dir / 'images'\n",
    "    labels_dir = data_dir / 'labels'\n",
    "    \n",
    "    print(f\"Loading data from {data_dir}...\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    bboxes = []\n",
    "    \n",
    "    image_files = sorted(list(images_dir.glob('*.jpg')))\n",
    "    \n",
    "    if max_samples:\n",
    "        image_files = image_files[:max_samples]\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "           \n",
    "        label_path = labels_dir / (img_path.stem + '.txt')\n",
    "        \n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "        \n",
    "        boxes = parse_yolo_label(label_path)\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            continue\n",
    "        \n",
    "        for box in boxes:\n",
    "            class_id, x_c, y_c, w, h = box\n",
    "            \n",
    "            if class_id >= num_classes:\n",
    "                continue  \n",
    "            \n",
    "            bbox = yolo_to_bbox(x_c, y_c, w, h, img_width, img_height)\n",
    "            \n",
    "            if use_full_image:\n",
    "                cropped = img\n",
    "            else:\n",
    "                cropped = crop_object_from_image(img, bbox)\n",
    "                \n",
    "                if cropped is None:\n",
    "                    continue\n",
    "            \n",
    "            images.append(cropped)\n",
    "            labels.append(classes[class_id])\n",
    "            bboxes.append(bbox)\n",
    "    \n",
    "    print(f\"Loaded {len(images)} objects from {len(image_files)} images\")\n",
    "    \n",
    "    return images, labels, bboxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541722c",
   "metadata": {},
   "source": [
    "#### HOG Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3830f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HOGFeatureExtractor:\n",
    "    def __init__(self, image_size=(128, 128), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "        self.image_size = image_size\n",
    "        self.hog_params = {\n",
    "            'orientations': orientations,\n",
    "            'pixels_per_cell': pixels_per_cell,\n",
    "            'cells_per_block': cells_per_block,\n",
    "            'block_norm': 'L2-Hys',\n",
    "            'channel_axis': None\n",
    "        }\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        if len(image.shape) ==3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "\n",
    "        resized = cv2.resize(gray, self.image_size)\n",
    "        return resized\n",
    "    \n",
    "    def extract_features(self, images):\n",
    "        single_image = False\n",
    "        if not isinstance(images, list):\n",
    "            images = [images]\n",
    "            single_image = True \n",
    "        \n",
    "        features_list = []\n",
    "        iterator = tqdm(images, desc=\"Extracting HOG\")\n",
    "\n",
    "        for img in iterator:\n",
    "            preprocessed = self.preprocess_image(img)\n",
    "            feature = hog(preprocessed, visualize=False, **self.hog_params)\n",
    "            features_list.append(feature)\n",
    "        \n",
    "        features = np.array(features_list)\n",
    "\n",
    "        return features[0] if single_image else features\n",
    "\n",
    "    def visualize(self, image):\n",
    "        preprocessed = self.preprocess_image(image)\n",
    "        \n",
    "        hog_params_viz = self.hog_params.copy()\n",
    "        \n",
    "        features, hog_image = hog(\n",
    "            preprocessed, \n",
    "            visualize=True, \n",
    "            **hog_params_viz\n",
    "        )\n",
    "        \n",
    "        hog_image = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "        \n",
    "        return features, hog_image, preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31fa32",
   "metadata": {},
   "source": [
    "#### SVM Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e05cbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SVMClassifier:\n",
    "    def __init__(self, kernel='rbf', C=1.0, gamma='scale'):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "        self.training_time = None\n",
    "        self.testing_time = None\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(f\"Training SVM (kernel={self.kernel}, C={self.C})...\")\n",
    "        print(f\"Training samples: {len(X_train)}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Feature scaling (fit on training data)\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        # Label encoding\n",
    "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
    "        \n",
    "        # Check class distribution\n",
    "        unique, counts = np.unique(y_train_encoded, return_counts=True)\n",
    "        print(f\"   Classes: {len(unique)}, Distribution: {dict(zip(unique, counts))}\")\n",
    "        \n",
    "        # SVM training\n",
    "        self.model = SVC(\n",
    "            kernel=self.kernel,\n",
    "            C=self.C,\n",
    "            gamma=self.gamma,\n",
    "            probability=True,  \n",
    "            random_state=42,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        self.model.fit(X_train_scaled, y_train_encoded)\n",
    "        \n",
    "        self.training_time = time.time() - start_time\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Training completed in {self.training_time:.2f} seconds\")\n",
    "        print(f\"Support vectors: {self.model.n_support_}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        y_pred_encoded = self.model.predict(X_test_scaled)\n",
    "        return self.label_encoder.inverse_transform(y_pred_encoded)\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        return self.model.predict_proba(X_test_scaled)\n",
    "\n",
    "    def evaluate(self, X_test, y_test, dataset_name='Test'):\n",
    "        print(f\"Evaluating on {dataset_name} set...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_test_encoded = self.label_encoder.transform(y_test)\n",
    "        y_pred_encoded = self.label_encoder.transform(y_pred)\n",
    "\n",
    "        pass #do it later.. (nov 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c43d449",
   "metadata": {},
   "source": [
    "#### Sliding Window Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowDetector:\n",
    "    def __init__(self, classifier, feature_extractor, scales=[0.5, 0.75, 1.0, 1.25, 1.5], step_size=32, confidence_threshold=0.5, nms_threshold=0.3):\n",
    "        self.classifier = classifier\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.scales = scales\n",
    "        self.step_size = step_size\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.nms_threshold = nms_threshold\n",
    "\n",
    "        (W, H) = self.feature_extractor.image_size\n",
    "        self.window_size = (H, W)\n",
    "\n",
    "    def sliding_window(self, image, window_size, step_size):\n",
    "        h, w = image.shape[:2]\n",
    "        win_h, win_w = window_size\n",
    "\n",
    "        for y in range(0, h - win_h + 1, step_size):\n",
    "            for x in range(0, w - win_w + 1, step_size):\n",
    "                window = image[y:y+win_h, x:x+win_w]\n",
    "                yield (x, y, window)\n",
    "\n",
    "    def compute_iou(self, box1, box2):\n",
    "        x1_1, y1_1, x2_1, y2_1 = box1\n",
    "        x1_2, y1_2, x2_2, y2_2 = box2\n",
    "                \n",
    "        x1_i = max(x1_1, x1_2)\n",
    "        y1_i = max(y1_1, y1_2)\n",
    "        x2_i = min(x2_1, x2_2)\n",
    "        y2_i = min(y2_1, y2_2)\n",
    "\n",
    "        iw = max(0, x2_i - x1_i)\n",
    "        ih = max(0, y2_i - y1_i)\n",
    "        intersection = iw * ih\n",
    "\n",
    "        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "        union = area1 + area2 - intersection\n",
    "\n",
    "        return intersection / union if union > 0 else 0\n",
    "\n",
    "    def non_max_suppression(self, detections):\n",
    "        if len(detections) == 0:\n",
    "            return []\n",
    "\n",
    "        detections = sorted(detections, key=lambda x: x[5], reverse=True)\n",
    "\n",
    "        keep = []\n",
    "        while len(detections) > 0:\n",
    "            current = detections[0]\n",
    "            keep.append(current)\n",
    "\n",
    "            detections = detections[1:]\n",
    "            filtered =[]\n",
    "\n",
    "            for detection in detections:\n",
    "                iou = self.compute_iou(current[0:4], detection[0:4])\n",
    "                if iou < self.nms_threshold:\n",
    "                    filtered.append(detection)\n",
    "\n",
    "            detections = filtered\n",
    "\n",
    "        return keep\n",
    "\n",
    "    def detect(self, image):\n",
    "        detections = []\n",
    "        \n",
    "        (H_win, W_win) = self.window_size\n",
    "\n",
    "        iterator = tqdm(self.scales, desc=\"Detecting\")\n",
    "        for scale in iterator:\n",
    "            h, w = image.shape[0:2]\n",
    "            new_h, new_w = int(h * scale), int(w * scale)\n",
    "            resized = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "            if new_h < H_win or new_w < W_win:\n",
    "                continue\n",
    "\n",
    "            windows_list = list(self.sliding_window(resized, self.window_size, self.step_size))\n",
    "    \n",
    "            windows_images = [win for (_,_,win) in windows_list]\n",
    "\n",
    "            if len(windows_images) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Extract HOG features (batch)\n",
    "            features = self.feature_extractor.extract_features(windows_images)\n",
    "\n",
    "            # Predict (batch)\n",
    "            predictions = self.classifier.predict(features)\n",
    "            confidences = self.classifier.predict_proba(features)\n",
    "\n",
    "            for (x,y, _), pred, conf in zip(windows_list, predictions, confidences):\n",
    "                for class_idx, conf_val in enumerate(conf):\n",
    "                    if conf_val >= self.confidence_threshold:\n",
    "                        scale_factor = 1.0 / scale\n",
    "                        x1 = int(x * scale_factor)\n",
    "                        y1 = int(y * scale_factor)\n",
    "                        x2 = int((x + W_win) * scale_factor)\n",
    "                        y2 = int((y + H_win) * scale_factor)\n",
    "\n",
    "                        class_name = self.classifier.label_encoder.inverse_transform([class_idx])[0]\n",
    "                        detections.append([x1, y1, x2, y2, class_name, conf_val])\n",
    "                \n",
    "        if len(detections) > 0:\n",
    "            detections = self.non_max_suppression(detections)\n",
    "\n",
    "        return detections\n",
    "\n",
    "        \n",
    "    def visualize_detections(self, image, detections, save_path=None):\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.patches as patches\n",
    "        \n",
    "        fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "        ax.imshow(image)\n",
    "        \n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(classes)))\n",
    "        class_to_color = {cls: colors[i] for i, cls in enumerate(classes)}\n",
    "        \n",
    "        for (x1, y1, x2, y2, class_name, confidence) in detections:\n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), x2-x1, y2-y1,\n",
    "                linewidth=2,\n",
    "                edgecolor=class_to_color.get(class_name, 'red'),\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "\n",
    "            label = f\"{class_name}: {confidence:.2f}\"\n",
    "            ax.text(\n",
    "                x1, y1-5,\n",
    "                label,\n",
    "                bbox=dict(facecolor=class_to_color.get(class_name, 'red'), alpha=0.7),\n",
    "                fontsize=10,\n",
    "                color='white',\n",
    "                weight='bold'\n",
    "            )\n",
    "        \n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Found {len(detections)} objects\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb22ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (COMP9517)",
   "language": "python",
   "name": "comp9517"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
